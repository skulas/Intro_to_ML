{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arthur Samuel\n",
    "(1959)<br>\n",
    "Field of study that gives computers the ability to learn without being explicitly programmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tom Mitchell\n",
    "(1998)<br>\n",
    "A computer program is said to learn from experience `E` with respect to some task `T` and some performance measure `P`, if its performance on `T` as measured by `P`, improves with `E`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Learning Algorithms\n",
    "[Source](https://blogs.sas.com/content/subconsciousmusings/2017/04/12/machine-learning-algorithm-use/?utm_source=facebook&utm_medium=cpc&utm_campaign=analytics-global&utm_content=US_interests-conversions) for further reading\n",
    "\n",
    "### Supervised learning\n",
    "\n",
    "Supervised learning algorithms make predictions based on a set of examples. For example, historical sales can be used to estimate the future prices. With supervised learning, you have an input variable that consists of labeled training data and a desired output variable. You use an algorithm to analyze the training data to learn the function that maps the input to the output. This inferred function maps new, unknown examples by generalizing from the training data to anticipate results in unseen situations.\n",
    "\n",
    "**Classification**<br>\n",
    "When the data are being used to predict a categorical variable, supervised learning is also called classification. This is the case when assigning a label or indicator, either dog or cat to an image. When there are only two labels, this is called binary classification. When there are more than two categories, the problems are called multi-class classification.\n",
    "\n",
    "**Regression**<br>\n",
    "When predicting continuous values, the problems become a regression problem.\n",
    "\n",
    "**Forecasting**<br>\n",
    "This is the process of making predictions about the future based on the past and present data. It is most commonly used to analyze trends. A common example might be estimation of the next year sales based on the sales of the current year and previous years.\n",
    "\n",
    "### Semi-supervised learning\n",
    "The challenge with supervised learning is that labeling data can be expensive and time consuming. If labels are limited, you can use unlabeled examples to enhance supervised learning. Because the machine is not fully supervised in this case, we say the machine is semi-supervised. With semi-supervised learning, you use unlabeled examples with a small amount of labeled data to improve the learning accuracy.\n",
    "\n",
    "### Unsupervised learning\n",
    "When performing unsupervised learning, the machine is presented with totally unlabeled data. It is asked to discover the intrinsic patterns that underlies the data, such as a clustering structure, a low-dimensional manifold, or a sparse tree and graph.\n",
    "\n",
    "**Clustering**<br>\n",
    "Grouping a set of data examples so that examples in one group (or one cluster) are more similar (according to some criteria) than those in other groups. This is often used to segment the whole dataset into several groups. Analysis can be performed in each group to help users to find intrinsic patterns.\n",
    "\n",
    "**Dimension reduction**<br>\n",
    "Reducing the number of variables under consideration. In many applications, the raw data have very high dimensional features and some features are redundant or irrelevant to the task. Reducing the dimensionality helps to find the true, latent relationship.\n",
    "\n",
    "### Reinforcement learning\n",
    "Reinforcement learning analyzes and optimizes the behavior of an agent based on the feedback from the environment.  Machines try different scenarios to discover which actions yield the greatest reward, rather than being told which actions to take. Trial-and-error and delayed reward distinguishes reinforcement learning from other techniques.\n",
    "\n",
    "\n",
    "**Learning Theory**<br>\n",
    "Study of how and why (mathematically) a learning algorithm works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concepts\n",
    "\n",
    "\n",
    "## Feature\n",
    "\n",
    "Anything in the world that we believe to have any impact on the value we are trying to predict (and can be measured).\n",
    "\n",
    "\n",
    "## Sample\n",
    "\n",
    "A sample is a collection of values given to the features for a single result (predicted or known).<br>\n",
    "If we are trying to predict how many hairs you have on your head basd on Age, Weight, Gender, Niegborhood, Soccer Team.<br>\n",
    "Each person we measure the Age, Weight, ... is a sample.<br>\n",
    "Each sample is a vector and we write it as $X=[x_1, x_2, ..., x_n]$<br>\n",
    "To list the samples we use an upper index and write them as a column vector:<br>\n",
    "\n",
    " \\begin{align}\n",
    "     \\begin{bmatrix}\n",
    "     X^0 \\\\\n",
    "     X^1 \\\\\n",
    "     \\vdots \\\\\n",
    "     X^m\n",
    "     \\end{bmatrix}\n",
    "     &=\n",
    "     \\begin{bmatrix}\n",
    "         [x_1^0,x_2^0,...,x_n^0] \\\\\n",
    "         [x_1^1,x_2^1,...,x_n^1] \\\\\n",
    "         \\vdots \\\\\n",
    "         [x_1^m,x_2^m,...,x_n^m] \\\\\n",
    "     \\end{bmatrix}\n",
    " \\end{align} \n",
    "\n",
    "\n",
    "## Scaling and Normalization\n",
    "\n",
    "In our example, gender: $g\\in[0,1]$ and weight: $wgt\\in[20,180]$.<br>\n",
    "Scaling is the action of making the magnitude of all features similar.<br>\n",
    "A good normalization method would be:\n",
    "\n",
    "\\begin{equation*}\n",
    "    x_n = \\frac{x-x_m}{x_M-x_m}\n",
    "\\end{equation*}\n",
    "\n",
    "where<br>\n",
    "\n",
    "- $x_n$: normalized x<br>\n",
    "- $x_m$: the **minimum** value x can get<br>\n",
    "- $x_M$: the **MAXimum** value x can get<br>\n",
    "\n",
    "\n",
    "## Target\n",
    "\n",
    "In the case of suppervised learning, the target or label is the actual result for a sample.<br>\n",
    "For `Age`=45, `Weight`=90, `Gender`=Female, `Neigborhood`=Villa Tachito, `Soccer Team`=Boca Jrs the **Target** would be 100 hairs on the head.<br>\n",
    "We symbolyze the targets for all our samples with vector $Y$:\n",
    "\n",
    " \\begin{align}\n",
    "     \\begin{bmatrix}\n",
    "         y^0 \\\\\n",
    "         y^1 \\\\\n",
    "         \\vdots \\\\\n",
    "         y^m\n",
    "     \\end{bmatrix}\n",
    "     &=\n",
    "     Y\n",
    " \\end{align}\n",
    "\n",
    "\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "$H_\\theta(X) = b + \\theta_1*x_1 + ... + \\theta_k*x_k=y$<br>\n",
    "Where $X=[x_i]$ is a single sample. The features/parameters we use to predict a result. Age, weight, gender, neigborhood, etc.<br>\n",
    "$\\theta_i$ are the weights we give to each parameter. These are the values we change during learning ittereations to improve the accuracy of our estimation.\n",
    "$b$ is the bias, a value we use to fine tune the hypothesis. We usually use $\\theta_0$ and $x_0=1$ so we get $b=\\theta_0*x_0$<br>\n",
    "$y$ is the value we predicted using the sample $X$ and the weights $\\theta_i$.<br>\n",
    "So we get:\n",
    "\n",
    " \\begin{align}\n",
    "     \\begin{bmatrix}\n",
    "         X^0 \\\\\n",
    "         X^1 \\\\\n",
    "         \\vdots \\\\\n",
    "         X^m\n",
    "     \\end{bmatrix}\n",
    "     &.\n",
    "     \\begin{bmatrix}\n",
    "         \\theta_0 \\\\\n",
    "         \\theta_1 \\\\\n",
    "         \\vdots \\\\\n",
    "         \\theta_n\n",
    "     \\end{bmatrix}\n",
    "     &=\n",
    "     \\begin{bmatrix}\n",
    "         [x_0^0,x_1^0,...,x_n^0] \\\\\n",
    "         [x_0^1,x_1^1,...,x_n^1] \\\\\n",
    "         \\vdots \\\\\n",
    "         [x_0^m,x_1^m,...,x_n^m] \\\\\n",
    "     \\end{bmatrix}\n",
    "     &.\n",
    "     \\begin{bmatrix}\n",
    "         \\theta_0 \\\\\n",
    "         \\theta_1 \\\\\n",
    "         \\vdots \\\\\n",
    "         \\theta_n\n",
    "     \\end{bmatrix}\n",
    "     &=\n",
    "     \\begin{bmatrix}\n",
    "         h_{\\theta}(x^1) \\\\\n",
    "         h_{\\theta}(x^2) \\\\\n",
    "         \\vdots \\\\\n",
    "         h_{\\theta}(x^m) \\\\\n",
    "     \\end{bmatrix}\n",
    " \\end{align} \n",
    "\n",
    "\n",
    "\n",
    "## Cost Function\n",
    "\n",
    "So, the hypothesis predicts a value on one hand, on the other we have the real value for a sample (in the training set).<br>\n",
    "There is a diffrence between the hypothesis and the target value.<br>\n",
    "The cost function defines a metric to decide what is the distance between the target and the hypothesis.<br>\n",
    "The most trivial cost function would be RMS (_root mean square_) but it is not always the best<br>\n",
    "The process of learning, in many algorithms, concists on reducing the cost function. It is done by calculating the hypothesis for a value, comparing it with the target, updating the weights and trying again. Doing this until the cost function reaches a minimum.<br>\n",
    "Note, the cost function is a function of the weights $\\theta_i$ and not the samples.<br>\n",
    "For example:\n",
    "\n",
    "![A](./screen-shot-2014-11-14-at-3-21-44-pm.png)\n",
    "\n",
    "**Note:**<br>\n",
    "We ussually mark with **$n$** the number of **features** and with **$m$** the number of **samples**<br>\n",
    "\n",
    "\n",
    "## Hyperparametes\n",
    "These are the parameters we use to conifugre the algorithm itself. Even-though the hyperparams are not a function of the features or their values, they depend on the values.\n",
    "\n",
    "\n",
    "## Grid Search\n",
    "Looking for the set of hyperparameters that turn to be the best for our use of the algorithm. There are many ways to perform Grid Search.<br>\n",
    "One popular Grid Search method is called _k-folds_. In which we take the training data, split it into a training set and a testing set.<br>\n",
    "One round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set). To reduce variability, in most methods multiple rounds of cross-validation are performed using different partitions, and the validation results are combined (e.g. averaged) over the rounds to estimate a final predictive model. [Wikipedia](https://en.wikipedia.org/wiki/Cross-validation_(statistics%29)\n",
    "\n",
    "![A](./K-fold_cross_validation_EN.jpg)\n",
    "\n",
    "\n",
    "## Confusion Matrix\n",
    "![A](./confusion_matrix2.png)\n",
    "\n",
    "\n",
    "## Under/Over Fitting\n",
    "_Underfitting_ occurrs when the trained model is too general, meaning it would predict partially well, but would miss many samples due to a bit higher variance.<br>\n",
    "_Overfitting_ happens when our trained model is too specific to the training data. Meaning it will only predict correctly data that is **too** similar to the training set and would miss predictions on a more generalized data set.<br>\n",
    "\n",
    "![A](./overfitting-logreg-ex.png)\n",
    "\n",
    "\n",
    "## Dimension Reduction\n",
    "<a name='dimensionreduction'></a>There are problems which involve hundreeds of features. Dimension reduction is the action of defining new, **less**, features that are enough to describe and predict our target.<br>\n",
    "Dimension reduction is useful for data visualization, to ease the understanding of the data. It can also be useful to improve the prediction performance.\n",
    "There are many methods, here I state two. PCA and tSNE.\n",
    "\n",
    "![A](./Dimensionality.png)\n",
    "\n",
    "### PCA\n",
    "Principal Component Analysis consists on looking for the features with the highest variance and using them as the new reduced features.\n",
    "\n",
    "### tSNE\n",
    "t-Distributed Stochastic Neighbor Embedding is a recursinve method to reduce dimensions by searching for near neighboors.<br>\n",
    "**Interesting Note**<br>\n",
    "Even-though you can embed the data into any number of dimensions, it won't necesarily improve the embedding as one would expect.\n",
    "\n",
    "Beautiful [hands on](https://distill.pub/2016/misread-tsne/) demo.<br>\n",
    "This is [the page](https://lvdmaaten.github.io/tsne/) where the method inventor centralizes all info about it.<br>\n",
    "[This Demo](http://projector.tensorflow.org/) is much easier to understand example. Taken lots of texts, the tSNE decides which words are related to each other (or photos).\n",
    "\n",
    "\n",
    "## Ensembles\n",
    "Creating ensembles involves aggregating the results of different models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Popular Algorithms\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "![Alt](./multiple-linear-regression-16-638.jpg \"txt\")\n",
    "\n",
    "- The outcome (the value we predict) is continuous<br>\n",
    "For any given of the independent paramter **X** we can predict any value for the predicted value **Y**<br>\n",
    "Given the RPM value of the engine what would be the power we could expect.<br>\n",
    "- Example<br>\n",
    "**Diabetes dataset**<br>\n",
    "Ten baseline variables: age, sex, body mass index, average blood pressure and six blood serum measurements.<br>\n",
    "The values were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.<br>\n",
    "**Data Set Characteristics**<br>\n",
    "Number of Instances: 442<br>\n",
    "Number of Attributes:<br>\n",
    "First 10 columns are numeric predictive values.<br>\n",
    "Target: Column 11 is a quantitative measure of disease progression one year after baseline<br>\n",
    "**Attributes**:<br>\n",
    "Age, Sex, Body mass index, Average blood pressure, S1, S2, S3, S4, S5, S6<br>\n",
    "**Note**:<br>\n",
    "Each of these 10 feature variables have been _mean centered and scaled by the standard deviation times_ `n_samples` (i.e. the sum of squares of each column totals 1).<br>\n",
    "[Source URL](http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(__doc__)\n",
    "\n",
    "\n",
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# display(diabetes.DESCR)\n",
    "\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "plt.xlabel('Patient Weight')\n",
    "plt.ylabel('1 Year Disease Progression')\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To think together**\n",
    "Let's say we are a real estate agent in Alaska.<br>\n",
    "We want to predict the price of an Igloo given it's radius.<br>\n",
    "We believe there is a linear relation between the area of the Igloo and it's price<br>\n",
    "The thing is the area of the igloo is proportional to $r^2$<br>\n",
    "_How do we find a linear regression to predict igloo price based on its radius?_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The outcome (the value we predict) is discrete<br>\n",
    "For any given of the independent paramter **X** we can predict one of a few options for prediction **Y**<br>\n",
    "Given the grades and sleeping culture of the student would he pass or not the test.\n",
    "- Approach\n",
    " 1. Define an hypothesis built of the parameters\n",
    " 1. Build Cost Function<br>\n",
    " The distance between the hyptesis and the true value\n",
    " 1. Define your metrics (How to decide how \n",
    " 1. Reduce Cost Function\n",
    "   1. Iterate the **Trating Set**\n",
    "   1. Udate hypotesis weights\n",
    " 1. Validate your final hypotesis on the **Testing Set**\n",
    "- Example<br>\n",
    "Change a linear regression to logistic by asking 'Would this igloo cost more than 200k?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Desicion Tree\n",
    "In a desicion tree you lay out options for each feature and investigate the possible outcomes of choosing those options.<br>\n",
    "The idea of a decision tree is to divide the data set into smaller data sets based on the descriptive features until you reach a small enough set that contains data points that fall under one label/target. [From this explanation](https://medium.com/@SeattleDataGuy/what-is-a-decision-tree-algorithm-4531749d2a17)<br>\n",
    "\n",
    "![A](./DecisionTree.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Features\n",
    "In the case you have many options for a feature (or it's a continuous feature such as time) you slit the possible values into cathegories or boundaries and test the values against this quantization.\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- Easy to implement (relatively)\n",
    "- Do not require big data for training\n",
    "- There is no need to scale or normalize the data.\n",
    "\n",
    "### Disvantages\n",
    "- Likely to overfit noisy data (data with high variance, with fluctuations around values)\n",
    "\n",
    "### Pruning\n",
    "A method to reduce the tree depth by detecting branches and paths that do not contribute to the outcome.<br>\n",
    "Prunning is espcially useful to **reduce overfitting** (but not only)\n",
    "\n",
    "### Notes\n",
    "\n",
    "- A feature value can be asked more than once (but it's not very common)\n",
    "- The order in which you ask the questions may have impact on the prediction. \n",
    "- _Gini Index_:<br>A sub class of decision trees are the _binary_ decision trees, which each node has only two exits.<br>The impurity (or purity) measure used in building decision tree in CART is **Gini** Index. The decision tree built by CART algorithm is always a binary decision tree (each node will have only two child nodes)<br>**CART** algorithm: **C**lassification **A**nd **R**egression **T**ree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is an ensemble of a few Desicion trees.\n",
    "\n",
    "- Bagging<br>has a single parameter, which is the **number of trees**. All trees are fully grown binary tree (unpruned) and at each node in the tree one searches over all features to find the feature that best splits the data at that node.\n",
    "- Random Forests<br>have 2 parameters\n",
    " - The first parameter is the same as bagging (the number of trees)\n",
    " - The second parameter (unique to randomforests) is _mtry_ which is how many features to search over to find the best feature. this parameter is usually $\\frac{1}{3}*D$ for regression and $\\sqrt(D)$ for classification. thus during tree creation randomly mtry number of features are chosen from all available features and the best feature that splits the data is chosen.\n",
    "- Bootstraping<br>Multiple decision trees each trained on a different sample of the data.<br>Because bootstrapping involves sampling with replacement, some of the data in the sample is left out of each tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN\n",
    "**k** **N**earest **N**eighbors<br><a name='knn'></a>\n",
    "The idea is to predict the label of a sample by looking at the nearest samples in the training data.<Br>\n",
    "The distance is easy to imagine on two or three dimensions. In more dimensions you need a metric to define distance between samples. For example: Hamming distance, Large Margin Nearest Neighbor or Neighbourhood components analysis.<br>\n",
    "$k$ is the number of closest samples to test the value. If you have two classes, $k$ should be odd to avoid tie.<br>In a more general speaking, $k$ should not be a product of the number of classes.<br>\n",
    "Look at the impact of the value you chose for $k$:\n",
    "![a](./knn_example.png)<Br>\n",
    "What happens when k=3 and when k=5?<br>\n",
    "A drawback of the basic \"majority voting\" classification occurs when the class distribution is skewed<br>\n",
    "Other drawback is that to find the closest samples you need to calculate the distances to lots of samples, which may be very time consuming for large $D$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "**S**upport **V**ector **M**achine<br>\n",
    "![a](./SVM_Ilustation.png)\n",
    "\n",
    "SVM detects a _road_ between the classes of the samples. Then predicts by deciding on which side of the road is the sample.<br>\n",
    "It doesn't just detect the road, but the widest possible road:\n",
    "![a](./svmmargin2.jpg)\n",
    "\n",
    "**Hyperplane**<br>\n",
    "Is the center of the _road_ the separates between the classes. The hyperplance is always one dimnesion less than the number of features, the dimension of the data.\n",
    "![a](./hyperplanes.jpg)\n",
    "\n",
    "**Kernel**<Br>\n",
    "What happens when the data cannot be separated by a linear hyperplane?<br>\n",
    "The kernel is the function that determines the shape of the hyperplane:\n",
    "![a](./nonsep_svm_rbf.png)<Br>\n",
    "in this example the best choice for the kernel would be RBF, **R**adial **B**asis **F**unction.<br>\n",
    "There are a few standard kernels. Yet, you can define any function to be your kernel. If you go deeper into Kernel you'll see it is not necesary to solve the function thus your can chose a very nasty kernel if it suits you data shape.\n",
    "\n",
    "**Feature Space vs Input Space**<br>\n",
    "These two become confusing when discussing SVMs. Even they are similar they are different, Same Same but Different...<br>\n",
    "Feature space refers to the n-dimensions where your variables live (not including a target variable, if it is present). The term is used often in ML literature because a task in ML is feature extraction, hence we view all variables as features. For example, consider the data set with:\n",
    "\n",
    "- Target\n",
    " - y≡ Thickness of car tires after some testing period\n",
    "- Variables\n",
    " - $x_1$≡ distance travelled in test\n",
    " - $x_2$≡ time duration of test\n",
    " - $x_3$≡ amount of chemical _C_ in the tires\n",
    "\n",
    "The feature space is $R^3$, or more accurately, in $R^{3+}$ (the positive quadrant) as all the $X$ variables can only be positive quantities. Domain knowledge about tires might suggest that the speed the vehicle was moving at is important, hence we generate another variable, $x_4$ (this is the feature extraction part):\n",
    "\n",
    "$x_4≡\\frac{x_1}{x_2}$ the speed of the vehicle during testing.\n",
    "\n",
    "**Mapping** the input space into feature space.<br>\n",
    "The input is mapped into variables through the function $\\phi$, from $R^3$ to $R^4$:\n",
    "\n",
    "$\\phi(x_1,x_2,x_3)=(x_1,x_2,x_3,\\frac{x_1}{x_2})$\n",
    "\n",
    "**Example**\n",
    "![a](./input_vs_feature_space.png)\n",
    "\n",
    "Using a Kernel to compute a non-linearly separable _input_ into a higher dimension linearly separable _features_.\n",
    "\n",
    "**More**<br>\n",
    "[Here](https://www.youtube.com/watch?v=_PwhiWxHK8o) you can find an **amazing** lecture with the math behind SVMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks\n",
    "ANNs<br>\n",
    "Computing systems inspired by the biological neural networks of the brain. The performance progressively improves on tasks (_i.e. Learns_) by considering examples, generally without task-specific programming.<br>\n",
    "For example, in image recognition. The examples could be photos labeled as 'CAT' or 'NOT CAT'. After learning many examples the performance is measured by how many times it recognized correctly whether there is a cat or not.<br>\n",
    "The learning process should be generic (regarding the content of the images). In the process evolves a set of relevant characteristics from the learning material that is processed. \n",
    "\n",
    "![a](./NN-with-components-w11-etc.png)\n",
    "\n",
    "In common ANN implementations, the signal at a connection between neurons is a real number, and the output of each neuron is calculated by a non-linear function of the sum of its inputs. Neurons and connections typically have a weight that adjusts as learning proceeds.\n",
    "\n",
    "### Neuron\n",
    "An ANN is based on a collection of connected units or nodes called _neurons_. Each connection between neurons transmits a value from one to another. The neuron that receives the signal can process it and then signal neurons connected to it.\n",
    "\n",
    "### Weight\n",
    "Is the importance / relevance each input to neuron has. The weight values are changed on each learning itteration.\n",
    "\n",
    "### Activation\n",
    "The inputs of one layer of neurons are connected to the inputs of the next layer.<br>\n",
    "What if we need the inputs of the neuron to comply with some limitations? To be only possitive, for example.<br>\n",
    "In such cases between layers we add an activation layer, which is, a layer that all that it does is transform the outputs of one layer to correct data for the next layer.<br>\n",
    "#### ReLU\n",
    "The most popular activation function today is the **Re**ctifier **L**inear **U**nit. What it does is to allow only possitive inputs:<br>\n",
    "$f(x) = x^+ = max(0,x)$<br>\n",
    "$x$ is the input to the neuron.\n",
    "#### Softmax\n",
    "Softmax is another popular activation function that reduces any real value to the close segment [0,1]:\n",
    "![a](./softmax.png)\n",
    "\n",
    "\n",
    "### Deep Nets\n",
    "Deep network is an ensemble of many layers of neural networks.<br>\n",
    "Deep nets have outstanding results when trained. The thing is they require huge data sets till they reach their potential performance.\n",
    "\n",
    "### Backprop\n",
    "Back Propagation<br>\n",
    "To improve performance of a network, erros flow in the opposite direction to the data to correct each network weights.\n",
    "\n",
    "### Transfer Learning\n",
    "Transfer learning or inductive transfer is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.<br>\n",
    "For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Some Neural Network Examples\n",
    "\n",
    "#### Feedforward\n",
    "Artificial neural networks where the connections between units do not form a cycle. Feedfoward neural networks were the first type of artificial neural network invented and are simpler than their counterpart, recurrent neural networks. They are called feedforward because information only travels forward in the network (no loops), first through the input nodes, then through the hidden nodes (if present), and finally through the output nodes.<br>\n",
    "From this [amazing website](https://brilliant.org/wiki/feedforward-neural-networks/) about mathematics.\n",
    "\n",
    "![a](./feedfwdnn.png)\n",
    " \n",
    "#### Recurrent\n",
    "The idea behind RNNs is to make use of sequential information. In a traditional neural network we assume that all inputs (and outputs) are independent of each other. But for many tasks that’s a very bad idea. If you want to predict the next word in a sentence you better know which words came before it. RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being depended on the previous computations. Another way to think about RNNs is that they have a “memory” which captures information about what has been calculated so far. In theory RNNs can make use of information in arbitrarily long sequences, but in practice they are limited to looking back only a few steps. Here is what a typical RNN looks like:\n",
    "\n",
    "![a](./rnn.jpg)\n",
    "_A recurrent neural network and the unfolding in time of the computation involved in its forward computation._\n",
    "\n",
    "- $x_t$ is the input at time step t. For example, $x_1$ could be a one-hot vector corresponding to the second word of a sentence.\n",
    "- $s_t$ is the hidden state at time step t. It’s the “memory” of the network. $s_t$ is calculated based on the previous hidden state and the input at the current step: $s_t=f(U*x_t + W*s_{t-1})$. The function $f$ usually is a nonlinearity such as tanh or ReLU.  $s_{-1}$, which is required to calculate the first hidden state, is typically initialized to all zeroes.\n",
    "- $o_t$ is the output at step $t$. For example, if we wanted to predict the next word in a sentence it would be a vector of probabilities across our vocabulary. $o_t = \\mathrm{softmax}(V*s_t)$.\n",
    "\n",
    "Taken from [this greate tutorial](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)\n",
    "\n",
    "\n",
    "\n",
    "**Example**<br>\n",
    "LSTM **L**ong **S**hort **T**erm **M**emory(Primitive version of RNNs) used to play music. [Duet between computer and human](https://experiments.withgoogle.com/ai/ai-duet/view/).\n",
    "\n",
    "#### Autoencoder\n",
    "A neural network that is trained to attempt to copy its input to its output. Internally, it has a hidden layerh that describes a code used to represent the input. The network may be viewed as consisting of two parts: an encoder functionh=$f(x)$ and a decoder that produces a reconstructionr=$g(h)$. If an autoencoder succeeds in simply learning to set $g(f(x)) =x$ everywhere, then it is not especially useful. Instead, autoencoders are designed to be unable to learn to copy perfectly. Usually they are restricted in ways that allow them to copy only approximately, and to copy only input that resembles the training data. Because the model is forced to prioritize which aspects of the input should be copied, it often learns useful properties of the data.<br>\n",
    "From this [online book](http://www.deeplearningbook.org)\n",
    "\n",
    "![a](./autoencoders.png)\n",
    "\n",
    "#### Convolutional\n",
    "A neural network that uses filters to detect features in the input.<br>\n",
    "The CNNs are quiet complicated. [A beatiful explanation](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/) can be found here.<br>\n",
    "Let's say we have a one bit image (black and white)\n",
    "![a](./conv_image_example.png)\n",
    "(this image is black where 1 and white where 0)\n",
    "Now we define a filter (AKA _kernel_ or _feature detector_)\n",
    "![a](./conv_filter_example.png)\n",
    "Now we scan our image with the filter and write how many times the 1's in the filter are also 1 in the image:\n",
    "![a](./convolution_schematic.gif)\n",
    "\n",
    "The matrix formed by sliding the filter over the image and computing the dot product is called the _Convolved Feature_ or _Activation Map_ or the _Feature Map_. It is important to note that filters act as feature detectors from the original input image.<br>\n",
    "To see how different filters have different impact on images see [this site](https://docs.gimp.org/en/plug-in-convmatrix.html).<br>\n",
    "Different filters detect different features:<br>\n",
    "![a](./conv_filters_different.gif)\n",
    "What you see is how two filters detect different features on the same image.<br>\n",
    "Now, once you have the features that were extracted from a labeled image, you can use them to look for them on an unlabled image and make desicions accordingly.\n",
    "\n",
    "**Example**<br>\n",
    "A [fun game](https://teachablemachine.withgoogle.com/) demonstrating CNN use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "Unsupervised machine learning is the machine learning task of inferring a function to describe hidden structure from \"unlabeled\" data.<br>\n",
    "Since the examples given to the learner are unlabeled, there is no evaluation of the accuracy of the structure that is output by the relevant algorithm—which is one way of distinguishing unsupervised learning from supervised learning and reinforcement learning.\n",
    "\n",
    "### Applications\n",
    "- Behavioural Analysis<br>\n",
    "Predict invdividual action based on collective beheaviour.<br>\n",
    "Detect a driver is very likely to have an accident based on others in his area...\n",
    "- Anomality Detection<br>\n",
    "Detect our driver is very likely to have an eccident, based on his own history till now...<br>\n",
    "Detect entry or exit point of contracts or stocks holdings.<br>\n",
    "Fraud Detection\n",
    "- Patterns Detection<br>\n",
    "Learn DNA mapping by inputing DNA pictures, parameters and observations.\n",
    "- Density Estimation<br>\n",
    "Building an estimation for an additional parameter based on the data we have.\n",
    "\n",
    "### Methods\n",
    "- <a href=#dimensionreduction>Dimension Reduction</a><br>\n",
    "When we need to detect which are the most useful inputs or features in our set.<br>\n",
    "- Custer Analysis<br>\n",
    "Look at the data values and detect grouping similarities, such as <a href=#knn>kNNs</a>\n",
    "- Neural Networks\n",
    "    - SOMs<br>\n",
    "    **S**elf **O**rganizing **M**aps produce a low-dimensional (typically two-dimensional), discretized representation of the input space of the training samples, called a _map_, and is therefore a method to do dimensionality reduction. Self-organizing maps differ from other neural networks as they apply competitive learning as opposed to error-correction learning in supervised learning.\n",
    "    - ART<br>\n",
    "    The primary intuition behind the **A**daptinve **R**esonance **T**heory model is that object identification and recognition generally occur as a result of the interaction of 'top-down' observer expectations with 'bottom-up' sensory information. The model postulates that 'top-down' expectations take the form of a memory template or prototype that is then compared with the actual features of an object as detected by the senses. This comparison gives rise to a measure of category belongingness. As long as this difference between sensation and expectation does not exceed a set threshold called the 'vigilance parameter', the sensed object will be considered a member of the expected class\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning\n",
    "**RL** Learning algorithm based on taking actions in an environment so as to maximize some notion of cumulative reward.<br>\n",
    "\n",
    "### Applications\n",
    "The problem, due to its generality, is studied in many other disciplines\n",
    "\n",
    "- Game theory\n",
    "- Control theory\n",
    "- Operations research\n",
    "- Information theory\n",
    "- Simulation-based optimization\n",
    "- Multi-agent systems\n",
    "- Swarm Intelligence\n",
    "- Genetic algorithms\n",
    "\n",
    "### Example\n",
    "![a](./RL_Example.png)\n",
    "This is a collective problem the players need to solve together.\n",
    "- The players cannot talk to each other.\n",
    "- Each player has two buttons. Red and Blue.\n",
    "- They get points only when they tap on a button and nobody else taps a button of the same color.\n",
    "- They can get between 0.0 to 10.0 points\n",
    "- If they tap one after the other quickly, the reward grows on each tap.\n",
    "- They get more points as the successful taps are evenly distributed among all players (for 4 consecutive successful taps, the max points is get if each player tapped once)\n",
    "- If they both tap togeter, they get noting and the next time somebody taps the reward restarts from 0.1.\n",
    "\n",
    "In the image above, thanks to **P1** they got additional 1.1 points and thanks to **P2** they got 3.7 points.\n",
    "\n",
    "**Parametrization**\n",
    "- At each step _t_ each agent (player)\n",
    "    - Executes action $a_t$ (or not, if doesn't push any button)\n",
    "    - Receives observation $o_t$ which could be how many points they got in step _t_\n",
    "    - Receives a reward $rb_t$ if pressed the blue button and $rr_t$ if pressed the red button\n",
    "- The Environment\n",
    "    - Receives action $a_t$\n",
    "    - Emits observation $o_{t+1}$\n",
    "    - Emits the rewards $rb_{t+1}$ and $rr_{t+1}$ to the players that took action\n",
    "    \n",
    "**Real World Example**<br>\n",
    "The ALOHA network problem\n",
    "\n",
    "- Couples of users want to use the same _N_ network channels to transmit packets, without the hability to communicate with other user couples.\n",
    "- At each transmission quant, each users decides whether to transmit or not.\n",
    "- If a user succeeds to transmit a packet it gets an ACK from his couple.\n",
    "- If more than one use transmits over the same channel at the same time, we assume no message was transmitted.\n",
    "_ **The Goal:** Find a distributed method for maximizing network utilization\n",
    "\n",
    "When the guys at Rephael used RL for solving the quest, they tried three approaches:\n",
    "- General Rewarding: All agents get rewards for successfull transmissions.\n",
    "- Private Rewarding: Only the agent that got the message through gets rewarded.\n",
    "- Fair General Rewarding: All agents get rewarded proportionally to the general number of transmitted packages (like in our game).\n",
    "\n",
    "**The Results**\n",
    "\n",
    "![a](./RL_GeneralReward.png)\n",
    "For **General Reward**, since everybody go the same points, the optimal procedure was that **two** couples transmit all the time and all the rest shut up. (Comunism doesn't work in channel optimization)\n",
    "\n",
    "![a](./RL_PrivateReward.png)\n",
    "When agents were **privately rewarded** all participants had to find how to devide the time slots so everybody can transmit. (Homo homini lupus - i.e. Adam le Adam Zeev)\n",
    "\n",
    "![a](./RL_FairReward.png)\n",
    "When the reward was **Proportional to** the messages all participants sent, the strategy found was to hold the channel until somebody else attempts to transmit (a packet is dropped - for those who are still awake) and then release the channel for the other agent.\n",
    "\n",
    "**The Optimal** channel utilization was achieved when each agent was **rewarded privately**.\n",
    "\n",
    "For further reading here is [a research](https://arxiv.org/pdf/1704.02613.pdf) regarding this example and [a lecture](https://github.com/DataHackIL/DataConf/blob/master/DataConf_2017/DataConf_2017_Rafael.pdf) based on this research by the same guy. I bulit this section based on the latter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Wrap Up\n",
    "\n",
    "### ML Areas\n",
    "![a](./machinelearningmap.png)\n",
    "\n",
    "### ML algorithms cheat sheet\n",
    "![a](./ml_map.png)\n",
    "\n",
    "### Matching between meta data and model\n",
    "![a](./machine-learning-cheet-sheet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "260px",
    "width": "470px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
