{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Driver Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the basics to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your path to make sure we are good to go:\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load general functions by exectuing `%load [python file]`<br>\n",
    "Use `%save -f '...` to save changes into the utils file. Or use `%%writefile`. To open the doc on each use `%save?` or `%%writefile?` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load 'eze_utils.py'\n",
    "def concatLists(headList, tailList):\n",
    "    conctd = [headList, tailList]\n",
    "    newList = sum(conctd, [])\n",
    "    \n",
    "    return newList\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# aa = list(np.arange(1,6))\n",
    "# bb = list(np.arange(12,25))\n",
    "# dd = concatLists(aa,bb)\n",
    "# ee = np.stack(cc, axis=1)\n",
    "# print(len(aa))\n",
    "# print(*aa, sep=',')\n",
    "# print(*bb, sep=',')\n",
    "# print(*dd, sep=',')\n",
    "# print(*ee, sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load CSV** File into panda table<br>\n",
    "**Sort** the table by the apearances of each name (Counter sorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    panda_table = pd.read_pickle('./ArielQueryResults_SaftyLvlAsNum.pkl')\n",
    "    print('Loaded the data from existing file')\n",
    "except FileNotFoundError:\n",
    "    print('Binary version of data not found, parsing the CSV.')\n",
    "    panda_table = pd.read_csv('ArielQueryResults_SaftyLvlAsNum.csv', parse_dates=['Event_Time_IL_Time'])\n",
    "    panda_table.to_pickle('./ArielQueryResults_SaftyLvlAsNum.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Table Columns:\\n' + str(panda_table.keys()))\n",
    "print('Total Samples In Data = ', str(len(panda_table['Trip_ID'])))\n",
    "print('Data Type = ', type(panda_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available **DIFFERENT Events In Data Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allEvents = set(panda_table['Event_Name'])\n",
    "display(allEvents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find **driver with most number of events**<br>\n",
    "- Define a **sub table** for this driver<br>\n",
    "- Sort events of _top driver_ by the event time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drivers_hist_sorted = list(Counter(panda_table['Driver_Name']).keys())\n",
    "top_driver_table = panda_table[panda_table['Driver_Name'] == drivers_hist_sorted[0]]\n",
    "top_driver_table = top_driver_table.sort_values(by='Event_Time_IL_Time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(drivers_hist_sorted[0:3])\n",
    "print(top_driver_table.head(3)['Event_Time_IL_Time'])\n",
    "print(top_driver_table.tail(3)['Event_Time_IL_Time'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the **First Trip** of the _top driver_<br>\n",
    "Build a **new table** for the first trip<br>\n",
    "**Remove** `Trip Start` and `Trip End` events from trip table (The first and last row of each trip, `iloc[1:-1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTripFromDriverTable(driverTable, tripId):\n",
    "    tripTable = driverTable[driverTable['Trip_ID'] == tripId]\n",
    "    tripTable = tripTable.iloc[1:-1]\n",
    "#     print('First trip ID: ' + str(tripId))\n",
    "    return tripTable\n",
    "\n",
    "firstTripTripId = top_driver_table['Trip_ID'][0]\n",
    "top_trip = getTripFromDriverTable(top_driver_table, firstTripTripId)\n",
    "# print(top_trip['Event_ID','Event_Name'].head(5))\n",
    "# print(top_trip['Event_Name'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building sub tables out of _top trip_ table. Figuring out the times.\n",
    "'Time_from_Trip_Start_secs', 'Time_from_Trip_End_secs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.concat([top_trip['Event_Name'],top_trip['Time_from_Trip_Start_secs'],top_trip['Time_from_Trip_End_secs']], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lastIx = len(top_trip['Time_from_Trip_End_secs'])-1\n",
    "top_trip['Time_from_Trip_End_secs'].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Time Series\n",
    "**Time Unit** is how many seconds passed between two items in the array. This value should remain **constant**, otherwise it would generate a time bend.<br>\n",
    "The **Trip Length** is in the data: `['Time_from_Trip_End_secs'][0]` secs.\n",
    "The **Array Length**, i.e. number of items in the time series, is a direct result of the trip length and time unit and should be given by:\n",
    "\n",
    "\\begin{equation*}\n",
    "arrayLength = \\frac{tripLength}{timeUnit}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "Let's build an array of _arraySize_ entries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kTimeUnit = 7 ## Assuming events happen at least 7 seconds away from each other of the same event type\n",
    "\n",
    "# initArr = [0] * base_array_size # a template of an empty feature array. Not working, uses the same instance even when trying to copy.\n",
    "def calculateArraySizeForTrip(trip):\n",
    "    tripLength = trip['Time_from_Trip_Start_secs'].iloc[-1]\n",
    "    # timeUnit = floor(tripLength/base_array_size)\n",
    "    arraySize = ceil(tripLength / kTimeUnit);\n",
    "    # print('Trip Length = ' + str(tripLength))\n",
    "    # print('Time Unit = ' + str(kTimeUnit) + ' (const)')\n",
    "    \n",
    "    return arraySize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each index in the array represents `Time Unit` seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove trip start and trip end events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events Sparse Matrix\n",
    "Create a sparse matrix for all the events.\n",
    "It will be a DataFrame, where the column is the event name and the value is an array of zeroes except where event happened.\n",
    "The time of the event is got by the event time `Time_from_Trip_Start_secs column` devided by the time unit floored to int.\n",
    "The use this int as the array index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary of arrays way, pure python...\n",
    "# differentEvents = set(top_trip['Event_Name'])\n",
    "# print(differentEvents)\n",
    "\n",
    "# def buildSparseMatrix__(tripTable, timeU = kTimeUnit):\n",
    "#     tripSparseMatrix = {}\n",
    "#     for eventName in differentEvents:\n",
    "#         tripSparseMatrix[eventName] = [0]*arraySize\n",
    "\n",
    "#     for row in tripTable.itertuples():\n",
    "#         eventName = row.Event_Name\n",
    "#         longAxl = row.Longitudinal_Acceleration_g\n",
    "#         latAxl = row.Lateral_Acceleration_g\n",
    "#         timeFromStart = row.Time_from_Trip_Start_secs\n",
    "#         ix = int(timeFromStart / timeU)\n",
    "#         tripSparseMatrix[eventName][ix] = longAxl + latAxl\n",
    "#         # print(str(ix) + ' - ' + str (timeFromStart) + ' .. ' + eventName + ' .. ' + str(longAxl) + ',' + str(latAxl)) #str(row[1]))\n",
    "#     return tripSparseMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame way\n",
    "# Define the columns for data analysis\n",
    "trip_cols = set(allEvents) # duplicate the set\n",
    "trip_cols.add('Speed_km_h')\n",
    "trip_cols.add('Driver_id')\n",
    "trip_cols.add('Trip_ID')\n",
    "#     trip_cos.add('Index')\n",
    "\n",
    "trip_cols.remove('Estimated trip end')\n",
    "trip_cols.remove('Estimated trip start')\n",
    "trip_cols.remove('Trip end')\n",
    "trip_cols.remove('Trip start')\n",
    "# trip_cols.remove('Collision Suspect')\n",
    "print(trip_cols)\n",
    "# Max speed for normalizing speed value\n",
    "kMaxSpeed = 120.0;\n",
    "kFixMatrixLength = 1000;\n",
    "\n",
    "def buildSparseMatrix(tripTable, arraySize, timeU=kTimeUnit, columns=trip_cols):\n",
    "    \n",
    "    index = range(kFixMatrixLength) # Build all matrices with the same size of the same length \n",
    "    #     print(tripTable['Trip_ID'])\n",
    "    #     tripId = tripTable    tripId = tripTable.loc[1,'Trip_ID']\n",
    "    tripId = tripTable['Trip_ID'][0]\n",
    "    driverId = tripTable['Driver_Name'][0]\n",
    "\n",
    "    # print(columns)\n",
    "    tripSparseMatrix = pd.DataFrame(index=index, columns=columns)\n",
    "    tripSparseMatrix = tripSparseMatrix.fillna(0.0) # Since zeroes crash a function, setting a small bias...\n",
    "    # tripSparseMatrix['Index'] = index\n",
    "    tripSparseMatrix['Trip_ID'] = tripId\n",
    "    tripSparseMatrix['Driver_id'] = driverId\n",
    "    # numOfSamples = tripSparseMatrix['Trip_ID'].count()\n",
    "    # print('Number of lines in matrix:', numOfSamples)\n",
    "\n",
    "    for row in tripTable.itertuples():\n",
    "        eventName = row.Event_Name\n",
    "        longAxl = row.Longitudinal_Acceleration_g\n",
    "        latAxl = row.Lateral_Acceleration_g\n",
    "        speedNorm = row.Speed_km_h / kMaxSpeed\n",
    "        \n",
    "        timeFromStart = row.Time_from_Trip_Start_secs\n",
    "        ix = int(timeFromStart / timeU) # - 1\n",
    "        if (ix >= kFixMatrixLength):\n",
    "            ix -= 1 # For extreme cases where the event happened at the end of the trip\n",
    "            print('Error ix=', str(ix), ' ~ ', str(timeFromStart / timeU), 'arraySize=', arraySize)\n",
    "        tripSparseMatrix.loc[ix, eventName] = longAxl + latAxl\n",
    "        tripSparseMatrix.loc[ix, 'Speed_km_h'] = speedNorm\n",
    "        \n",
    "        \n",
    "        # print(str(ix), ' - ', timeFromStart, ' - ', str(longAxl + latAxl))\n",
    "        # print(str(ix) + ' - ' + str (timeFromStart) + ' .. ' + eventName + ' .. ' + str(longAxl) + ',' + str(latAxl)) #str(row[1]))\n",
    "    return tripSparseMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## JUST CHECKING WHAT IT DOES\n",
    "# import numpy as np\n",
    "# np.array([np.arange(10)]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.array([np.arange(10)]*3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And the resulting sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arraySize = calculateArraySizeForTrip(top_trip)\n",
    "print('Array Size = ', arraySize)\n",
    "# tripSM = buildSparseMatrix(top_trip, kTimeUnit, arraySize)\n",
    "tripSM = buildSparseMatrix(arraySize=arraySize, tripTable=top_trip)\n",
    "print('Matrix Size:', str(tripSM.shape[0]), 'rows,', str(tripSM.shape[1]), 'cols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(top_trip)\n",
    "pd.set_option(\"display.max_rows\", 30) \n",
    "# display(tripSM.iloc[1:40])\n",
    "display(tripSM.head(10))\n",
    "display(tripSM.tail(10))\n",
    "\n",
    "# Print in case using the pure python matrix\n",
    "# for key in tripSM.keys():\n",
    "#     print(key + ': ' + str(tripSM[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Data for analysis for one **Driver**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recap. Each array in the sparse matrix is the normalized time series of an event.<br>\n",
    "Now we'll build on table for all trips of the top driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kMinNumberOfEventsInTrip = 4  # Exclusive (Min < n)\n",
    "\n",
    "def buildAllTripsFromDriverTable(driverTable):\n",
    "    # Was: driverTripIds = set(driverTable['Trip_ID'])\n",
    "    # but I'm not sure I can trust the set(...) order.\n",
    "    driverTripIds, indices = np.unique(driverTable['Trip_ID'], return_index=True)\n",
    "    driverTripIds = driverTable['Trip_ID'][sorted(indices)] #Undo the `unique` sort\n",
    "\n",
    "    numberOfTrips = len(driverTripIds)\n",
    "    print('Number of trips for driver ', driverTable['Driver_Name'][0], ': ' , str(numberOfTrips))\n",
    "    \n",
    "    driverMatrices = list()\n",
    "    shortestTripLen = 900000\n",
    "    longestTripLen = 0\n",
    "    shortTripsCounter = 0\n",
    "    # print(driverTripIds)\n",
    "    for tripId in driverTripIds:\n",
    "        tripTable = getTripFromDriverTable(tripId=tripId, driverTable=driverTable)\n",
    "        tripLen = tripTable.shape[0]\n",
    "        if ((shortestTripLen!=0) and (tripLen < shortestTripLen)):\n",
    "            shortestTripLen = tripLen\n",
    "        if (longestTripLen < tripLen):\n",
    "            longestTripLen = tripLen\n",
    "\n",
    "    #     print(str(tripId), str(tripLen))\n",
    "    #     if (tripId == 533803009):\n",
    "    #         display(trip_table)\n",
    "    #         trip_table = trip_table.reindex(columns=trip_table.keys(), index=range(tripLen))\n",
    "    #         trip_table = trip_table.reset_index(drop=True)\n",
    "    #         trip_table = trip_table.copy(deep=True)\n",
    "    #         display(trip_table)\n",
    "        if (tripLen > kMinNumberOfEventsInTrip):\n",
    "            tripTable = tripTable.reset_index(drop=True)\n",
    "            arraySize = calculateArraySizeForTrip(tripTable)\n",
    "            # tripId = trip_table['Trip_ID'][0]\n",
    "            # print('Trip ID = ', str(tripId))\n",
    "            tripSM = buildSparseMatrix(tripTable=tripTable, arraySize=arraySize)\n",
    "            driverMatrices.append(tripSM)\n",
    "        else:\n",
    "            shortTripsCounter += 1\n",
    "\n",
    "\n",
    "\n",
    "    print('Shortest trip length =', str(shortestTripLen), 'Longest trip Len', str(longestTripLen))\n",
    "    print('Number of trips discarded =', shortTripsCounter)\n",
    "    driverData = pd.concat(driverMatrices)\n",
    "    driverData = driverData.reset_index(drop=True)\n",
    "    \n",
    "    display(driverMatrices[-2].tail(5))\n",
    "    display(driverData.tail(3))\n",
    "    \n",
    "    return driverData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build the sparse matrix of our **top driver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_data = buildAllTripsFromDriverTable(top_driver_table)\n",
    "\n",
    "driver_data = driver_data.fillna(0.0)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 60) \n",
    "print('Total driver data table size:', driver_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(driver_data.head(60))\n",
    "# display(driver_data.tail(60))\n",
    "# find already built table\n",
    "testTable = driver_data[driver_data['Trip_ID'] == 0]\n",
    "print('Number of trips with Trip_ID = Zero:', testTable.shape[0])\n",
    "# display(testTable)\n",
    "# display(driver_data.iloc[[16108,16109,16110]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testTable = top_driver_table[top_driver_table['Trip_ID'] == 526996324.0]\n",
    "# display(testTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's calculate the same for an Additional Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_driver_table = panda_table[panda_table['Driver_Name'] == drivers_hist_sorted[1]]\n",
    "next_driver_table = next_driver_table.sort_values(by='Event_Time_IL_Time').reset_index(drop=True)\n",
    "\n",
    "lookingForUsefulTrip = True\n",
    "ix = 0\n",
    "firstTrip = pd.DataFrame()\n",
    "while(lookingForUsefulTrip):\n",
    "    firstTripTripId = next_driver_table['Trip_ID'][ix]\n",
    "    firstTrip = getTripFromDriverTable(next_driver_table, firstTripTripId)\n",
    "    if (firstTrip.shape[0] > kMinNumberOfEventsInTrip):\n",
    "        lookingForUsefulTrip = False\n",
    "    else:\n",
    "        ix+=1\n",
    "arraySize = calculateArraySizeForTrip(firstTrip)\n",
    "print('Array size', arraySize)\n",
    "\n",
    "next_driver_data = buildAllTripsFromDriverTable(next_driver_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('For driver', driver_data['Driver_id'][0])\n",
    "print('For driver', next_driver_data['Driver_id'][0], 'there are', str(next_driver_data.shape[0]), 'rows')\n",
    "display(next_driver_data.head(20))\n",
    "display(next_driver_data.tail(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate both drivers data and build a labels array\n",
    "One label for each trip. The label value is 0 for the first driver and 1 for the second.<br>\n",
    "Even-though we could have calculated this during data build, we do it here for readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Data\n",
    "Now we concatenate the drivers data in the same order as we've built the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDetectionFullMatrix = pd.concat([driver_data, next_driver_data])\n",
    "featuresDetectionFullMatrix = featuresDetectionFullMatrix.reset_index(drop=True)\n",
    "featuresDetectionFullMatrix['Index'] = featuresDetectionFullMatrix.index\n",
    "featuresDetectionFullMatrix = featuresDetectionFullMatrix.drop('Driver_id', axis=1)\n",
    "display(featuresDetectionFullMatrix.head(3))\n",
    "display(featuresDetectionFullMatrix.tail(3))\n",
    "print('Matrix shape:', featuresDetectionFullMatrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove useless features\n",
    "Let's check now if there's any column that is **all zeros** and we can get rid of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonZeroMatrix = featuresDetectionFullMatrix!= 0\n",
    "nonZeroMatrix.any(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Speed Alert** appears to be all **zeros**, let's remove it from the table by coppying all other columns to a new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Speed alert column\n",
    "featuresDetectionFullMatrix = featuresDetectionFullMatrix.loc[:, (nonZeroMatrix.any(axis=0))]\n",
    "display(featuresDetectionFullMatrix.head(3))\n",
    "display(featuresDetectionFullMatrix.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's count how **much data** is the the non-zero features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(featuresDetectionFullMatrix.astype(bool).sum(axis=0))\n",
    "print('='*66)\n",
    "print('Data shape:', featuresDetectionFullMatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, based on the ouput above we remove Collisions too\n",
    "featuresDetectionFullMatrix = featuresDetectionFullMatrix.drop('Collision Suspect', axis=1)\n",
    "display(featuresDetectionFullMatrix.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Labels Array\n",
    "One label for each trip.<br>\n",
    "* **0** for first driver\n",
    "* **1** for second driver\n",
    "\n",
    "**NOTE**<br>\n",
    "May trips are discarded since there were no events during these trips, and that's the reason for the much less trips in the sparse data matrix than in the original data.<br>\n",
    "**Index**<br>\n",
    "Data indexing should be done using the `Trip_ID`s rather than a basic running 1..n index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many trips are dropped since they don't have enough events\n",
    "topDriverTripIds = set(driver_data['Trip_ID'])\n",
    "topDriverLabels = [0]*len(topDriverTripIds)\n",
    "topName = driver_data.loc[0, 'Driver_id']\n",
    "\n",
    "nextDriverTripIds = set(next_driver_data['Trip_ID'])\n",
    "nextDriverLabels = [1]*len(nextDriverTripIds)\n",
    "nextName = next_driver_data.loc[0, 'Driver_id']\n",
    "\n",
    "labels = concatLists(topDriverLabels, nextDriverLabels)\n",
    "print('Number of trips for', topName, ':', len(topDriverLabels), '. Will get Label 0')\n",
    "print('Number of trips for', nextName, ':', len(nextDriverLabels), '. Will get Label 1')\n",
    "print('Total number of labels:', str(len(labels)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index the Labels using the trip ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelsIndex = set(featuresDetectionFullMatrix['Trip_ID'])\n",
    "# display(np.unique(featuresDetectionFullMatrix['Trip_ID'], return_index=True))\n",
    "labelsIndex, indices = np.unique(featuresDetectionFullMatrix['Trip_ID'], return_index=True)\n",
    "indices=sorted(indices)\n",
    "# print('Shape of labelsIx =', labelsIndex.shape)\n",
    "# print('Shape of indices =', len(indices), ' type:', type(indices))\n",
    "\n",
    "labelsIndex = featuresDetectionFullMatrix['Trip_ID'][indices]\n",
    "testRange = slice(80,85)\n",
    "\n",
    "display(featuresDetectionFullMatrix[['Trip_ID','Speed_km_h']].loc[indices[testRange]])\n",
    "print('Type :', type(labelsIndex))\n",
    "print('Shape :', labelsIndex.shape)\n",
    "# display(labelsIndex[0:3], featuresDetectionFullMatrix['Trip_ID'])\n",
    "#         labelsIndex[-4:-1])\n",
    "\n",
    "# display(featuresDetectionFullMatrix[featuresDetectionFullMatrix['Trip_ID'].isin(labelsIndex.head(2))])\n",
    "\n",
    "# Turn the labels/targets into a series, as required by the features detector\n",
    "# labels = pd.Series(labels, index=range(1, 1+len(labels)))\n",
    "labels = pd.Series(labels, index=labelsIndex)\n",
    "display(labels[testRange])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "For time series in our matrix.<br>\n",
    "We'll extract features of the time series represented by each of the arrays in the sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh import select_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we split into two steps\n",
    "1\\. Extract all the features<br>\n",
    "If there is a file with previously found features, load it.<br>\n",
    "If not, start extracting features (tedious process that can take very long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features = extract_features(featuresDetectionFullMatrix, \n",
    "#                      column_id='Trip_ID', column_sort='Index',\n",
    "#                      default_fc_parameters=extraction_settings,\n",
    "#                      impute_function= impute)\n",
    "\n",
    "foundIt = False\n",
    "try:\n",
    "    restoredFeatures = pd.read_pickle('./all_features.pkl')\n",
    "    all_features = restoredFeatures\n",
    "    foundIt = True\n",
    "except FileNotFoundError:\n",
    "    print('Features file not found.')\n",
    "    foundIt = False\n",
    "\n",
    "if (foundIt):\n",
    "    print('** Features where restored from a previously saved file of all the features')\n",
    "else:\n",
    "    print('Start features extraction')\n",
    "    all_features = extract_features(featuresDetectionFullMatrix, \n",
    "        column_id='Trip_ID', column_sort='Index',\n",
    "        impute_function= impute)\n",
    "    all_features.to_pickle('./all_features.pkl')\n",
    "\n",
    "\n",
    "display('All features shape: ', type(all_features), all_features.shape)\n",
    "display(all_features.head(3))\n",
    "display(labels.head(3))\n",
    "\n",
    "display(all_features.loc[:][80:85])\n",
    "display(labels[80:85])\n",
    "\n",
    "display(all_features.tail(3))\n",
    "display(labels.tail(3))\n",
    "\n",
    "\n",
    "#     # verify file\n",
    "#     try:\n",
    "#         testRestore = pd.read_pickle('./all_features.pkl')\n",
    "#         if (all_features.equals(testRestore)):\n",
    "#             print('All Features were saved successfully')\n",
    "#         else:\n",
    "#             print('WARNING: FILE could not be savad, all features were not saved')\n",
    "#     except FileNotFoundError:\n",
    "#         print('ERROR: FILE could was not savad, all features were not saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, features = all_features.shape\n",
    "print('There are', samples, 'samples of', features, 'features each')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Detect the features that really have impact on the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    useful_features = pd.read_pickle('./useful_features.pkl')\n",
    "    print('Loading useful features from file succeeded')\n",
    "except FileNotFoundError:\n",
    "    print('Load existing useful features from file failed. Calculating useful features.')\n",
    "    useful_features = select_features(all_features, labels)\n",
    "    print('Saving calculated features to file.')\n",
    "    useful_features.to_pickle('./useful_features.pkl')\n",
    "\n",
    "\n",
    "print('Useful features:', type(useful_features), useful_features.shape)\n",
    "samples, features = useful_features.shape\n",
    "print('So now we have', samples, 'samples of', features, 'useful features each to try prediction')\n",
    "# display(all_features.head(3))\n",
    "display(useful_features.head(3))\n",
    "# display(all_features.tail(3))\n",
    "display(useful_features.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The system found **297 useful features** out ouf our data.<br>\n",
    "<s>A sparse matrix has **not enough information** to extract.<br>\n",
    "We'd need a more basic approach using less data, the data we have in a more condense form.</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring the friends from Scikit Learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D # for drawing 3D scatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ploting functions for visualising data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver_0 = 'Top Driver'\n",
    "driver_1 = 'Next Driver'\n",
    "\n",
    "def plot_pca(pca_data, titleStr, d0Name=driver_0, d1Name=driver_1, figSize=7, target=labels):\n",
    "    colors=['blue','red']\n",
    "    markers=['$0$', '$1$']\n",
    "    \n",
    "    fig = plt.figure(figsize=(figSize, figSize))\n",
    "    for dtix in range(len(colors)):\n",
    "        x = pca_data[:, 0][target == dtix]\n",
    "        y = pca_data[:, 1][target == dtix]\n",
    "        plt.scatter(x,y, c=colors[dtix], marker=markers[dtix])\n",
    "    \n",
    "    plt.legend([d0Name, d1Name], bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.title(titleStr)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PlotReductionTo3D(features3D, figSize = 5, labels=labels):\n",
    "    fig = plt.figure(figsize=(figSize,figSize))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    colors=['blue','red']\n",
    "    markers=['$0$', '$1$']\n",
    "\n",
    "    for dtix in range(len(colors)):\n",
    "        x = features3D[:, 0][labels == dtix]\n",
    "        y = features3D[:, 1][labels == dtix]\n",
    "        z = features3D[:, 2][labels == dtix]\n",
    "        plt.scatter(x,y,z, c=colors[dtix], marker=markers[dtix])\n",
    "\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.title(\"Data reduction to 3 dimensions\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated SVD\n",
    "truncated **S**ingular **V**alue **D**ecomposition.<br>\n",
    "This dimension reduction method is espcially good with sparse data as ours.<br>\n",
    "In the case of the tSVD we'll be not using the extracted features but the original time series instead.<br>\n",
    "tSVD is a nice place to start.<br>\n",
    "We'll generate a label for each line in our sparse matrix and attempt to learn something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelsIndex = featuresDetectionFullMatrix['Trip_ID'][indices]\n",
    "# testRange = slice(80,85)\n",
    "\n",
    "# display(featuresDetectionFullMatrix[['Trip_ID','Speed_km_h']].loc[indices[testRange]])\n",
    "\n",
    "topDriverNumOfSamples, numberOfColumns = driver_data.shape\n",
    "nextDriverNumOfSamples, numberOfColumns = next_driver_data.shape\n",
    "print('Top driver number of samples:', topDriverNumOfSamples)\n",
    "print('Next driver number of samples', nextDriverNumOfSamples)\n",
    "longLabels = np.concatenate( (np.zeros(topDriverNumOfSamples, dtype=np.int), np.ones(nextDriverNumOfSamples, dtype=np.int)), axis=0 )\n",
    "longLabels = pd.Series(longLabels) # , indices=featuresDetectionFullMatrix['Trip_ID'])\n",
    "\n",
    "display('Total samples: ' + str(topDriverNumOfSamples + nextDriverNumOfSamples))\n",
    "display(longLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdAlgo = 'arpack' # randomized\n",
    "tsvd = TruncatedSVD(n_components=2, random_state=33, algorithm=svdAlgo, tol=0.5)\n",
    "tsvd_scaled_result = tsvd.fit_transform(featuresDetectionFullMatrix)\n",
    "\n",
    "samples,features = tsvd_scaled_result.shape\n",
    "print('We have', samples,'samples of',features,'features (dimensions) each, meaning WE CAN PLOT THIS DATA!')\n",
    "figSize = 5\n",
    "display(featuresDetectionFullMatrix.head(1))\n",
    "plot_pca(tsvd_scaled_result, 'tSVD Reduction of scaled data.', figSize=figSize,target=longLabels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... too good to be true ...\n",
    "Let's try removing the index and the TripId from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparseMatrix = featuresDetectionFullMatrix.drop('Index', axis=1)\n",
    "# sparseMatrix = sparseMatrix.drop('Trip_ID', axis=1)\n",
    "sparseMatrix = featuresDetectionFullMatrix.drop('Index', axis=1)\n",
    "display(sparseMatrix.head(1))\n",
    "\n",
    "tsvd_scaled_result = tsvd.fit_transform(sparseMatrix)\n",
    "plot_pca(tsvd_scaled_result, 'tSVD Reduction of scaled data.', figSize=figSize,target=longLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd3D = TruncatedSVD(n_components=3, random_state=33, algorithm=svdAlgo, tol=0.5)\n",
    "tsvd3d_scaled_result = tsvd3D.fit_transform(sparseMatrix)\n",
    "PlotReductionTo3D(tsvd3d_scaled_result, figSize=10, labels=longLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this one looks horrible... don't give up.<br>\n",
    "~~Will try spliting the matrix into an array of matrices, each matrix in the array will be a trip.<br>\n",
    "Each trip matrix will be reshaped to an array, concatenating the rows one after the other~~<br>\n",
    "**Cut loss**: In our case, each sample consists on a trip. Each trip consists on a matrix. Analyzing data in this dimensionality is commonly used in _behavioral and biological analysis_.<br>\n",
    "I will pause my research on this direction, due to its complexity and lack of mature tools to quickly handle data in such dimensionality.<br>\n",
    "These papers deal with this area, I'll put them here for furure use.<br>\n",
    "[Algorithms for Time Series Clustering\n",
    "Applied to Biomedical Signals](./biosignal_timeseries_clustering_thesis.pdf)<br>\n",
    "[Clustering Algorithm for Human Behavior Recognition Based on Biosignal Analysis](human_behavior_clustering_biological_timeseries.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data for scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max value in entire feature set:\")\n",
    "print(useful_features.max(axis=1).max())\n",
    "print(\"-\"*80)\n",
    "print(\"Min value of the features:\")\n",
    "print(useful_features.min(axis=1).min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... we need to do scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = preprocessing.scale(useful_features)\n",
    "print(scaled_features.max())\n",
    "print(scaled_features.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce Number Of Features\n",
    "##### PCA\n",
    "**P**rincipal **C**omponent **A**nalysis tries to find the most relevant of the useful features we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_PCA = PCA(svd_solver='full', n_components=2)\n",
    "# full_PCA = PCA(svd_solver='arpack', n_components=2, tol=2.5)\n",
    "reduced_scaled_features_with_full = full_PCA.fit_transform(scaled_features)\n",
    "reduced_features_with_full = full_PCA.fit_transform(useful_features)\n",
    "samples,features = reduced_scaled_features_with_full.shape\n",
    "print('So now we have', samples,'samples of',features,'features (dimensions) each, meaning WE CAN PLOT THIS DATA!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing** the reduced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca(reduced_scaled_features_with_full, 'PCA from full scan of SCALED features', figSize=5)\n",
    "plot_pca(reduced_features_with_full, 'PCA from full scan of original features', figSize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really useful components, there is no way to separate the two groups.<br>\n",
    "There is no point on trying **kNN** (Nearest Neigbhors), the reduction is not giving anything useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *t-SNE*\n",
    "t-Distributed **S**tochastic **N**eighbor **E**mbedding\n",
    "Try reducing the dimensions of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=15, random_state=33, verbose=True)#, n_iter=1000, learning_rate=10)\n",
    "\n",
    "tsne15_scaled_result = tsne.fit_transform(scaled_features)\n",
    "tsne15_full_result = tsne.fit_transform(useful_features)\n",
    "\n",
    "plot_pca(tsne15_scaled_result, 'tSNE Reduction of scaled data, Perp=15', figSize=5)\n",
    "plot_pca(tsne15_full_result, 'tSNE Reduction of full features size', figSize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tsne.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=5, random_state=33, n_iter=500, learning_rate=105, verbose=True)\n",
    "tsne5_scaled_result = tsne.fit_transform(scaled_features)\n",
    "\n",
    "tsne.perplexity = 10\n",
    "tsne10_scaled_result = tsne.fit_transform(scaled_features)\n",
    "\n",
    "tsne.perplexity = 20\n",
    "tsne20_scaled_result = tsne.fit_transform(scaled_features)\n",
    "\n",
    "tsne.perplexity = 30\n",
    "tsne30_scaled_result = tsne.fit_transform(scaled_features)\n",
    "\n",
    "plot_pca(tsne5_scaled_result, 'tSNE Reduction of scaled data. Perp=5', figSize=5)\n",
    "plot_pca(tsne10_scaled_result, 'tSNE Reduction of scaled data. Perp=10', figSize=5)\n",
    "plot_pca(tsne20_scaled_result, 'tSNE Reduction of scaled data. Perp=20', figSize=5)\n",
    "plot_pca(tsne30_scaled_result, 'tSNE Reduction of scaled data. Perp=30', figSize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing the perplexity (the number of near neigbhors allowed) and performing quick trains we see that between 10 and 20 in we get useful reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=10, random_state=33, n_iter=1000, learning_rate=110, method='exact', verbose=True)\n",
    "tsne.perplexity = 10\n",
    "tsne10_scaled_result = tsne.fit_transform(scaled_features)\n",
    "\n",
    "tsne.perplexity = 11\n",
    "tsne11_scaled_result = tsne.fit_transform(scaled_features)\n",
    "\n",
    "tsne.perplexity = 12\n",
    "tsne12_scaled_result = tsne.fit_transform(scaled_features)\n",
    "\n",
    "tsne.perplexity = 13\n",
    "tsne13_scaled_result = tsne.fit_transform(scaled_features)\n",
    "\n",
    "tsne.perplexity = 14\n",
    "tsne14_scaled_result = tsne.fit_transform(scaled_features)\n",
    "\n",
    "tsne.perplexity = 15\n",
    "tsne15_scaled_result = tsne.fit_transform(scaled_features)\n",
    "\n",
    "tsne.perplexity = 16\n",
    "tsne16_scaled_result = tsne.fit_transform(scaled_features)\n",
    "\n",
    "\n",
    "\n",
    "figSize = 4\n",
    "plot_pca(tsne10_scaled_result, 'tSNE Reduction of scaled data. Perp=10', figSize=figSize)\n",
    "plot_pca(tsne11_scaled_result, 'tSNE Reduction of scaled data. Perp=11', figSize=figSize)\n",
    "plot_pca(tsne12_scaled_result, 'tSNE Reduction of scaled data. Perp=12', figSize=figSize)\n",
    "plot_pca(tsne13_scaled_result, 'tSNE Reduction of scaled data. Perp=13', figSize=figSize)\n",
    "plot_pca(tsne14_scaled_result, 'tSNE Reduction of scaled data. Perp=14', figSize=figSize)\n",
    "plot_pca(tsne15_scaled_result, 'tSNE Reduction of scaled data. Perp=15', figSize=figSize)\n",
    "plot_pca(tsne16_scaled_result, 'tSNE Reduction of scaled data. Perp=16', figSize=figSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tSNE reduce to 3D\n",
    "Let's give it a shot in 3D. Using perp = 30 as it got the lowest error in the 2D reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3, perplexity=30, random_state=33, n_iter=1000, learning_rate=105, method='exact', verbose=True)\n",
    "tsne_3Dscaled_result = tsne.fit_transform(scaled_features)\n",
    "PlotReductionTo3D(tsne_3Dscaled_result, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good (the scaled features, the original are less distributed)<br>\n",
    "#### Fine Tunning the tSNE\n",
    "Let's run cross validation with some tSNE hyperparameters to find the optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Configurable parameters of tsne')\n",
    "tsne.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into **training** set and **testing** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, labels, test_size=.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I think tSNE cannot be optimized as its cost function is not convex (it converges to different results given different initializations)\n",
    "# hyperparams = {'perplexity':[10,20,30,35,40],\n",
    "#               'learning_rate':[10,50,100,200],\n",
    "#               'method':['barnes_hut', 'exact']}\n",
    "\n",
    "# cvsne = GridSearchCV(tsne, hyperparams, cv=8, scoring='adjusted_rand_score') #split the samples into 8 folds (11 samples / fold)\n",
    "# cvsne.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate Desicion Tree as a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desicion_tree = DecisionTreeClassifier()\n",
    "desicion_tree.fit(X_train, y_train)\n",
    "print(classification_report(y_test,desicion_tree.predict(X_test)))\n",
    "n_training, n_features = X_train.shape\n",
    "print('Used features:', n_features, '. Number of training Samples:', n_training, '. Possible drivers', desicion_tree.n_classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**precision** (also called positive predictive value) is the fraction of relevant instances among the retrieved instances<br>\n",
    "**recall** (also known as sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. Both precision and recall are therefore based on an understanding and measure of relevance.<br>\n",
    "**f1-score** is the weighted harmonic mean between precision and recall.<br>\n",
    "**support** The number of occurrences of each label in y_true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **closer** precision and recall are **to 1.0 the** better the results are...<br>\n",
    "Even-though the results look good, they are not.<br>\n",
    "If the results are close to 0.5 for two possible targests (driver0 or driver1). 0.5 smells like a random picked driver for each trip.<br>\n",
    "Probably 0.5 is the worst result.<br>\n",
    "Yet, our results are slightly above 0.5, meaning if we take may trees and ask for what most of them think we may improve our classification. Let's try using Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Even-though we have lots of features and very few samples, I'll try to train a random forest. It probably won't work, but it's nice to practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randForest = RandomForestClassifier(n_estimators=20, max_features='auto')\n",
    "display(randForest.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `n_estimators`: Number of trees\n",
    "* `max_features`: The number of features to consider when looking for the best split\n",
    "* `bootstrap`: [Wikipedia](https://en.wikipedia.org/wiki/Bootstrap_aggregating). Similar to kFolds, split the trainig data into smaller sets (not exclusive) and using different series on each tree in the forest.\n",
    "\n",
    "[All Random Forest Hyperparams](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests hyperparams estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degs_of_freedom = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes': [None, 20, 50, 100, 200],\n",
    "    'oob_score': [True, False],\n",
    "#    'warm_start': [True, False]\n",
    "#     'bootstrap': [True, False] # bootstrap must be true. The GridSearch crashes if false.\n",
    "}\n",
    "\n",
    "# cv: number of kFolds\n",
    "# n_jobs: number of parallel jobs\n",
    "gridSearch = GridSearchCV(estimator=randForest, cv=8, param_grid=degs_of_freedom, n_jobs=3)\n",
    "\n",
    "# Train \n",
    "print('Training Set Size:', y_train.shape)\n",
    "gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see ...\n",
    "bestForest = gridSearch.best_estimator_\n",
    "print('Best score for training data:', gridSearch.best_score_)\n",
    "print('Best tree estimators:', bestForest.n_estimators, 'max features:', bestForest.max_features, 'max leaf nodes:', bestForest.max_leaf_nodes, 'oob_score', bestForest.oob_score, 'warm start:', bestForest.warm_start)\n",
    "testScore = gridSearch.score(X_test, y_test)\n",
    "print('Score on TEST data set:', testScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The training data consists of 88 trips total**<br>\n",
    "\n",
    "Results for **6 kFolds**:<br>\n",
    "This means 6 groups of 88/6 samples (trips) each.<br>\n",
    "Best score for training data: **0.551**<br>\n",
    "* Best tree estimators: 50 \n",
    "* max features: log2 \n",
    "* max leaf nodes: 50 \n",
    "* oob_score: False\n",
    "\n",
    "Results for **8 kFolds**:<br>\n",
    "This means 8 groups of 11 (88/8) trips each.\n",
    "Best score for training data: **0.602**<br>\n",
    "* Best tree estimators: 100 \n",
    "* max features: log2 \n",
    "* max leaf nodes: 50 \n",
    "* oob_score: True\n",
    "\n",
    "Finally, the score we got on the testing samples is horrible, probably the features we found are useless with random trees. Yet...<br>\n",
    "Let's use our best tree for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestForest = bestForest.fit(X=X_train, y=y_train)\n",
    "outofthebagScore = bestForest.oob_score\n",
    "print(\"Out of the bag score:\", outofthebagScore)\n",
    "\n",
    "treeScore = bestForest.score(X_test, y_test)\n",
    "print('Forest score after fitting:', treeScore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's measure the entire model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = bestForest.predict(X_test)\n",
    "print('Testing data size:', y_test.shape)\n",
    "print('Classification report of test and predicted')\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(20*'____')\n",
    "print('Confusion Matrix')\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is getting better.<br>\n",
    "To get better results I tried a few times to fit the forest using the train data. When got a result above 0.7, I used this forest for prediction and the results are really inspiring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tSNE and Random Forest\n",
    "Now we'll try to reduce the dimensionality of the data using tSNE and then use a random forest to classify our data, using the tSNE as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaled_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=36, perplexity=6, random_state=33, n_iter=5000, learning_rate=10, method='exact', verbose=True)\n",
    "tsne_output = tsne.fit_transform(scaled_features)\n",
    "print('New data size: ', tsne_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the 10 new feautres in the desicion tree.<br>\n",
    "First split the new data set into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tsne_output, labels, test_size=.2, random_state=33)\n",
    "print('Training set shape:', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check for the best forest for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "randForest = RandomForestClassifier(n_estimators=20, max_features=None, verbose=0)\n",
    "degs_of_freedom = {\n",
    "    'n_estimators': [10, 12, 15, 18, 20, 22, 24, 26, 30, 50],\n",
    "    'criterion':['entropy', 'gini'],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes': [None, 2, 5, 10, 15, 20],\n",
    "#     'oob_score': [True, False],\n",
    "#    'warm_start': [True, False]\n",
    "#     'bootstrap': [True, False] # bootstrap must be true. The GridSearch crashes if false.\n",
    "}\n",
    "\n",
    "# cv: number of kFolds\n",
    "# n_jobs: number of parallel jobs\n",
    "gridSearch = GridSearchCV(estimator=randForest, cv=8, param_grid=degs_of_freedom, n_jobs=3)\n",
    "\n",
    "# Train \n",
    "print('Training Set Size:', y_train.shape)\n",
    "gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's see ...\n",
    "bestForest = gridSearch.best_estimator_\n",
    "print('Best score for training data:', gridSearch.best_score_)\n",
    "print('Best tree estimators:', bestForest.n_estimators, 'max features:', bestForest.max_features, 'max leaf nodes:', bestForest.max_leaf_nodes, 'oob_score', bestForest.oob_score, 'warm start:', bestForest.warm_start)\n",
    "print('Forest desicion criterion:', bestForest.criterion)\n",
    "testScore = gridSearch.score(X_test, y_test)\n",
    "print('Score on TEST data set:', testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestForest = bestForest.fit(X=X_train, y=y_train)\n",
    "\n",
    "treeScore = bestForest.score(X_test, y_test)\n",
    "print('Forest score after fitting:', treeScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = bestForest.predict(X_test)\n",
    "print('Testing data size:', y_test.shape)\n",
    "print('Classification report of test and predicted')\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(20*'____')\n",
    "print('Confusion Matrix')\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not improving. After testing several tSNE and random forests, the results don't get much better.\n",
    "Using Random Forests directly brought better results than building a pipeline of tSNE -> Randomf Forest.<br>\n",
    "May be down the rowd it'd be worth doing some kind of estimator that loops and find the best hyperparams for the tSNE and Random Forest.<br>\n",
    "I'm pretty sure there's no strong relation between the trips data and the drivers, yet we'll do one last attempt.<br>\n",
    "Let's try using SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "**S**upport **V**ector **M**achine<br>\n",
    "[Beautiful explanation](http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html) about radial function kernel SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tSNE or Raw Data?\n",
    "Now we chose data.<br>\n",
    "Shall we use all the features we extracted from the time series, or only the few tSNE reduced from the entire set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tSNE or not\n",
    "use_tSNEAsImput = True\n",
    "\n",
    "X_train = {}\n",
    "y_train = {}\n",
    "X_test = {}\n",
    "y_test = {}\n",
    "RanState = 33\n",
    "\n",
    "if use_tSNEAsImput:\n",
    "    tsne = TSNE(n_components=12, perplexity=7, random_state=RanState, n_iter=5000, learning_rate=10, method='exact', verbose=True)\n",
    "    tsne_output = tsne.fit_transform(scaled_features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(tsne_output, labels, test_size=.2, random_state=RanState)\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_features, labels, test_size=.2, random_state=RanState)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialized an svm with some default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testSVM(svm, X_test=X_test, y_test=y_test, X_train=X_train, y_train=y_train):\n",
    "    testedSVM = svm.fit(X_train, y_train)\n",
    "    accu = testedSVM.score(X_test, y_test)\n",
    "    print('Initial svm accuracy: ', accu)\n",
    "    y_predict = testedSVM.predict(X_test)\n",
    "    print('Testing data size:', y_test.shape)\n",
    "    print('Classification report of test and predicted')\n",
    "    print(metrics.classification_report(y_test, y_predict))\n",
    "    print(20*'____')\n",
    "    print('Confusion Matrix')\n",
    "    print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someSvm = svm.SVC(kernel='rbf', random_state=RanState, C=10, gamma=0.1)\n",
    "\n",
    "#Let's check how this SVM performs\n",
    "testSVM(svm=someSvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! very nice! Let's check the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the SVM can be fine tuned to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperParamsFreedom =[\n",
    "    {\n",
    "        'C':[25, 50, 100, 150],\n",
    "        'gamma':[0.001, 0.005, 0.01, 0.1],\n",
    "        'kernel':['linear', 'poly', 'sigmoid', 'rbf']\n",
    "    }\n",
    "]\n",
    "# hyperParamsFreedom =[\n",
    "#     {\n",
    "#         'C':[1, 10, 100, 200],\n",
    "#         'gamma':[100, 10, 1, 0.1, 0.01],\n",
    "#         'kernel':['rbf', 'linear', 'poly', 'sigmoid']\n",
    "#     }\n",
    "# ]\n",
    "# hyperParamsFreedom =[\n",
    "#     {\n",
    "#         'C':[1, 10, 100, 200],\n",
    "#         'gamma':[100, 10, 1],\n",
    "#         'kernel':['rbf', 'linear', 'poly', 'sigmoid']\n",
    "#     },\n",
    "#     {\n",
    "#         'C':[0.1, 1, 10],\n",
    "#         'gamma':[10, 1, 0.1],\n",
    "#         'kernel':['rbf', 'linear', 'poly', 'sigmoid']\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "svmTuner = GridSearchCV(estimator=someSvm, param_grid=hyperParamsFreedom, cv=8, n_jobs=3)\n",
    "svmTuner.fit(X_train, y_train)\n",
    "tunedSVM = svmTuner.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see ...\n",
    "print('Best score for training data:', svmTuner.best_score_)\n",
    "print('Best ''C'':', tunedSVM.C)\n",
    "print('Best kernel:', tunedSVM.kernel)\n",
    "print('Best gamma:', tunedSVM.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how does the tuned SVM perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSVM(tunedSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuner perform worse than the SVM I created from my head.<br>\n",
    "It doesn't mean I'm lucky, but it means the SVM estimaor (Grid Search) generates an over fit SVM.<br>\n",
    "This data is useless. Let's try something else... <br>\n",
    "Building a sparse matrix of all acclereations, merging all events into a single accelerations column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================\n",
    "# Sparse Matrix of Acelerations\n",
    "Remove the distribution into events, just use speed and acceleration values (lateral and longitudinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's find the longest trip and set the matrix length and time unit accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useless, we need the longest trip, not the trip with most events in it\n",
    "# numberOfItemsForEachEventId = panda_table['Trip_ID'].value_counts()\n",
    "# if (len(numberOfItemsForEachEventId) != len(set(panda_table['Trip_ID']))):\n",
    "#     display('ALERT')\n",
    "# allTripIds = np.unique(panda_table['Trip_ID'])\n",
    "# firstId = allTripIds[0]\n",
    "# firstTrip = panda_table[panda_table['Trip_ID'] == firstId]\n",
    "# display('Id =', firstId)\n",
    "# display(firstTrip.head(2))\n",
    "# display(firstTrip.tail(2))\n",
    "\n",
    "# display(pd.concat([firstTrip['Event_Name'],firstTrip['Time_from_Trip_Start_secs'],firstTrip['Time_from_Trip_End_secs'],firstTrip['Event_Time_IL_Time']], axis=1))\n",
    "endEventsTable = panda_table[panda_table['Event_Name'] == 'Trip end']\n",
    "longestTripTime = endEventsTable['Time_from_Trip_Start_secs'][:].max()\n",
    "display('Longest trip = ' + str(longestTripTime) + 'secs')\n",
    "print('And', (longestTripTime / 60 / 60), 'hours')\n",
    "# display(endEventsTable.head(2))\n",
    "# display(endEventsTable.tail(2))\n",
    "display(endEventsTable[endEventsTable['Time_from_Trip_Start_secs'] == longestTripTime])\n",
    "\n",
    "# longestTripLookup = pd.concat([panda_table['Event_Name'],firstTrip['Time_from_Trip_Start_secs'],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK... 112 hours, hmmm. A bit long trip. It's like it had to refuel 20 times full tannk if traveling in a Renault fluence...<br>\n",
    "We need to search for the first RATIONAL lontest trip, let's do some manual work...<br>\n",
    "First we'll sort all the trip lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endEventsTable = endEventsTable.sort_values(['Time_from_Trip_Start_secs'], ascending=0)\n",
    "rowsRange = slice(0,20)\n",
    "# display(endEventsTable['Trip_ID'][rowsRange], endEventsTable['Time_from_Trip_Start_secs'][rowsRange]))\n",
    "display(endEventsTable[['Trip_ID','Time_from_Trip_Start_secs']].head(20))\n",
    "print('90K secs is ' + str(90000/60/60) + ' hours')\n",
    "# display(endEventsTable.tail(2))\n",
    "# display(featuresDetectionFullMatrix[['Trip_ID','Speed_km_h']].loc[indices[testRange]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the longest trip, Net length\n",
    "So we have too many _long trips_. . .<br>\n",
    "~~Let's just look only for trips shorter than five hours... 60 x 60 x 6 = 21600 secs.~~<br>\n",
    "Or event better, let's get rid of all the 'End Trips' and check for the latest kinematic event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildTripTable(tripId, dataTable=panda_table):\n",
    "    tripTable = dataTable[dataTable['Trip_ID'] == tripId]\n",
    "    tripTable = tripTable.sort_values(['Time_from_Trip_Start_secs'], ascending=1)\n",
    "    # Fix Index\n",
    "    newIndex = range(tripTable.shape[0])\n",
    "    tripTable.index = newIndex\n",
    "    \n",
    "    return tripTable\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Git rid of `Estimated_trip_end`, `Estimated_trip_start` and `Trip_end` events. These are junk events that make the trip longer without adding information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a 2 hours trip approach - less convenient\n",
    "# longestTripInSex = 60*60*2\n",
    "# possibleTrips = endEventsTable[endEventsTable['Time_from_Trip_Start_secs'] < longestTripInSex]\n",
    "# longestTripLength = possibleTrips['Time_from_Trip_Start_secs'][:].max()\n",
    "# longestTrip = possibleTrips[possibleTrips['Time_from_Trip_Start_secs'] == longestTripLength]\n",
    "# print('The longest trip is (' + str(longestTripLength / 60) + ' mins):')\n",
    "# longestTripId = longestTrip.Trip_ID.values[0]\n",
    "# #### longestTrip = panda_table[panda_table['Trip_ID'] == longestTripId]\n",
    "# #### longestTrip = longestTrip.sort_values(['Time_from_Trip_Start_secs'], ascending=1)\n",
    "# longestTrip = buildTripTable(tripId=longestTripId)\n",
    "\n",
    "# display(longestTrip)\n",
    "# print(str(longestTripId))\n",
    "\n",
    "\n",
    "# Removing all the End_Trip, Estimated_trip_end and Estimated_trip_start Events from the table.\n",
    "desiredEvents = set(allEvents) # duplicate the set\n",
    "desiredEvents.remove('Estimated trip end')\n",
    "desiredEvents.remove('Estimated trip start')\n",
    "desiredEvents.remove('Trip end')\n",
    "# Keep it, for being the zero of time desiredEvents.remove('Trip start')\n",
    "\n",
    "print('Desired Events:')\n",
    "display(desiredEvents)\n",
    "no_end_trip_full_table = panda_table[panda_table['Event_Name'].isin(desiredEvents)]\n",
    "\n",
    "# cleanup NaN \n",
    "no_end_trip_full_table = no_end_trip_full_table.fillna(0.0)\n",
    "# test = set(no_end_trip_full_table['Event_Name'])\n",
    "# display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the **longest trip** table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sortedTable = panda_table.sort_values('Event_Name');\n",
    "# tempTable1 = panda_table[panda_table.Event_Name != 'Estimated trip end']\n",
    "# tempTable1 = tempTable1.reindex()\n",
    "# tempTable2 = tempTable1[~tempTable1.Event_Name.str.contains(\"mated trip start\", case=True)].reindex()\n",
    "# no_end_trip_full_table = tempTable2[tempTable2.Event_Name != 'Trip end']\n",
    "\n",
    "\n",
    "# no_end_trip_full_table = panda_table.query('Event_Name != \"Trip end\" and Event_Name != \"Estimated trip start\" and Event_Name != \"Estimated trip end\"')\n",
    "# no_end_trip_full_table = panda_table.query('(Event_Name != \"Trip end\") and (Event_Name != \"Estimated trip start\")')\n",
    "# tetststs = (no_end_trip_full_table['Event_Name'].str.contains('ated trip en')==True)\n",
    "# display(tetststs == True)\n",
    "# no_end_trip_full_table = no_end_trip_full_table[no_end_trip_full_table['Event_Name'].str.contains(\"ated trip en\")]                     \n",
    "\n",
    "# no_end_trip_full_table = no_end_trip_full_table[no_end_trip_full_table.Event_Name != 'Estimated trip start']\n",
    "# no_end_trip_full_table = no_end_trip_full_table[no_end_trip_full_table.Event_Name != 'Estimated trip end']\n",
    "\n",
    "longestTripLength = no_end_trip_full_table['Time_from_Trip_Start_secs'][:].max()\n",
    "print('The longest trip is (' + str(longestTripLength / 60) + ' mins):')\n",
    "longestTripEnd = no_end_trip_full_table[no_end_trip_full_table['Time_from_Trip_Start_secs'] == longestTripLength]\n",
    "longestTripId = longestTripEnd.Trip_ID.values[0]\n",
    "longestTrip = buildTripTable(dataTable=no_end_trip_full_table, tripId=longestTripId)\n",
    "\n",
    "display(longestTrip[['Event_Name', 'Trip_ID', 'Speed_km_h']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we found a reasonable trip length, we need to see if there were any events after the length of the longest trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notGood = panda_table[(panda_table.Speed_km_h > 0) & (panda_table.Time_from_Trip_Start_secs > longestTripLength)]\n",
    "print(notGood.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happy!! Meaning our longest event is the latest an event can happen, so the matrix length could be `longest_trip_length / kTimeUnit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longAxlLbl = 'Longitudinal_Acceleration_g'\n",
    "latAxlLbl = 'Lateral_Acceleration_g'\n",
    "speedLbl = 'Speed_km_h'\n",
    "timeLbl = 'Time_from_Trip_Start_secs'\n",
    "syncLbl = 'Absolute_Time'\n",
    "trip_cols = ['Trip_ID', syncLbl, timeLbl, 'Driver_id', speedLbl, longAxlLbl, latAxlLbl]\n",
    "\n",
    "# trip_cols.remove('Collision Suspect')\n",
    "print(trip_cols)\n",
    "# Max speed for normalizing speed value\n",
    "kMaxSpeed = 120.0\n",
    "kTimeUnit = 7 # Let's set each line in the matrix to be 7 seconds.\n",
    "kFixMatrixLength = ceil(longestTripLength/kTimeUnit)\n",
    "print('Sparse matrices size:', kFixMatrixLength)\n",
    "\n",
    "def buildAxlSparseMatrix(tripTable, arraySize=kFixMatrixLength, timeU=kTimeUnit, columns=trip_cols):\n",
    "    index = range(kFixMatrixLength) # Build all matrices with the same size of the same length \n",
    "    \n",
    "    # Constants along a given matrix / trip\n",
    "    tripId = tripTable['Trip_ID'][0]\n",
    "    driverId = tripTable['Driver_Name'][0]\n",
    "\n",
    "    # print(columns)\n",
    "    tripSparseMatrix = pd.DataFrame(index=index, columns=columns)\n",
    "    tripSparseMatrix = tripSparseMatrix.fillna(0.0)\n",
    "    \n",
    "    tripSparseMatrix['Trip_ID'] = tripId\n",
    "    tripSparseMatrix['Driver_id'] = driverId\n",
    "    tripSparseMatrix[syncLbl] = index\n",
    "    tripSparseMatrix[timeLbl] = [timeU * t for t in index]\n",
    "\n",
    "    for row in tripTable.itertuples():\n",
    "        longAxl = row.Longitudinal_Acceleration_g\n",
    "        latAxl = row.Lateral_Acceleration_g\n",
    "        speedNorm = row.Speed_km_h / kMaxSpeed\n",
    "        \n",
    "        # Index in array is function of the time.\n",
    "        timeFromStart = row.Time_from_Trip_Start_secs\n",
    "        ix = int(timeFromStart / timeU)\n",
    "        \n",
    "        # For extreme cases where the event happened at the end of the trip\n",
    "        # If a trip is longer than (Time_Unit * kFixMatrixLength) seconds, this solution won't work (~1.5 hours trip)\n",
    "        if (ix >= kFixMatrixLength):\n",
    "            ix -= 1\n",
    "            print('Error ix=', str(ix), ' ~ ', str(timeFromStart / timeU), 'arraySize=', arraySize)\n",
    "            return pd.DataFrame(index=index, columns=columns) #return an empty table in case of overflow\n",
    "            \n",
    "        # += in case two events happen in the same time slot (witin TimeUnit seconds)\n",
    "#         tripSparseMatrix.loc[ix, timeLbl] = row.Time_from_Trip_Start_secs\n",
    "        tripSparseMatrix.loc[ix, longAxlLbl] += longAxl\n",
    "        tripSparseMatrix.loc[ix, latAxlLbl] += latAxl\n",
    "        tripSparseMatrix.loc[ix, speedLbl] = speedNorm   #if (currSpeed < speedNorm) else \n",
    "    \n",
    "    # Turn the NaN into Zero\n",
    "#     tripSparseMatrix = tripSparseMatrix.fillna(0.0)\n",
    "    return tripSparseMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topSparse = buildAxlSparseMatrix(longestTrip)\n",
    "display(topSparse.head(5))\n",
    "display(topSparse.tail(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use the **same two drivers** as we did in our previous data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drivers_hist_sorted = list(Counter(no_end_trip_full_table['Driver_Name']).keys())\n",
    "top_driver_table = no_end_trip_full_table[no_end_trip_full_table['Driver_Name'] == drivers_hist_sorted[0]]\n",
    "next_driver_table = no_end_trip_full_table[no_end_trip_full_table['Driver_Name'] == drivers_hist_sorted[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kMinNumberOfEventsInTrip = 3  # Exclusive (Min < n)\n",
    "\n",
    "def buildTripsTableListFromDriverTable(driverTable):\n",
    "    driverTripIds, indices = np.unique(driverTable['Trip_ID'], return_index=True)\n",
    "    driverTripIds = driverTable['Trip_ID'][sorted(indices)] #Undo the `unique` sort\n",
    "\n",
    "    numberOfTrips = len(driverTripIds)\n",
    "    print('Number of trips for driver ', driverTable['Driver_Name'][0], ': ' , str(numberOfTrips))\n",
    "    \n",
    "    driverMatrices = list()\n",
    "    shortestTripLen = 900000\n",
    "    longestTripLen = 0\n",
    "    shortTripsCounter = 0\n",
    "    # print(driverTripIds)\n",
    "    for tripId in driverTripIds:\n",
    "        tripTable = buildTripTable(dataTable=driverTable, tripId=tripId)\n",
    "        tripLen = tripTable.shape[0]\n",
    "        if ((shortestTripLen!=0) and (tripLen < shortestTripLen)):\n",
    "            shortestTripLen = tripLen\n",
    "        if (longestTripLen < tripLen):\n",
    "            longestTripLen = tripLen\n",
    "\n",
    "    #     print(str(tripId), str(tripLen))\n",
    "    #     if (tripId == 533803009):\n",
    "    #         display(trip_table)\n",
    "    #         trip_table = trip_table.reindex(columns=trip_table.keys(), index=range(tripLen))\n",
    "    #         trip_table = trip_table.reset_index(drop=True)\n",
    "    #         trip_table = trip_table.copy(deep=True)\n",
    "    #         display(trip_table)\n",
    "        if (tripLen > kMinNumberOfEventsInTrip):\n",
    "            tripTable = tripTable.reset_index(drop=True)\n",
    "#             arraySize = calculateArraySizeForTrip(tripTable)\n",
    "            # tripId = trip_table['Trip_ID'][0]\n",
    "            # print('Trip ID = ', str(tripId))\n",
    "            tripSM = buildAxlSparseMatrix(tripTable=tripTable) ## Make all matrices the same shape, arraySize=arraySize)\n",
    "            driverMatrices.append(tripSM)\n",
    "        else:\n",
    "            shortTripsCounter += 1\n",
    "\n",
    "\n",
    "\n",
    "    print('Shortest trip length =', str(shortestTripLen), 'Longest trip Len', str(longestTripLen))\n",
    "    print('Number of trips discarded =', shortTripsCounter)\n",
    "    driverData = pd.concat(driverMatrices)\n",
    "    driverData = driverData.reset_index(drop=True)\n",
    "    \n",
    "#     display(driverMatrices[-2].tail(5))\n",
    "#     display(driverData.tail(3))\n",
    "    \n",
    "    return driverData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_driver_table = top_driver_table.sort_values(by='Event_Time_IL_Time').reset_index(drop=True)\n",
    "next_driver_table = next_driver_table.sort_values(by='Event_Time_IL_Time').reset_index(drop=True)\n",
    "\n",
    "# display(top_driver_table.head(20))\n",
    "# display(next_driver_table.head(20))\n",
    "\n",
    "top_driver_data = buildTripsTableListFromDriverTable(top_driver_table)\n",
    "next_driver_data = buildTripsTableListFromDriverTable(next_driver_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Analysis Data\n",
    "First build **one matrix with both drivers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDataMatrix = pd.concat([top_driver_data, next_driver_data])\n",
    "fullDataMatrix = fullDataMatrix.reset_index(drop=True)\n",
    "fullDataMatrix.Absolute_Time = fullDataMatrix.index\n",
    "featuresDetectionFullMatrix = fullDataMatrix.drop('Driver_id', axis=1)\n",
    "display(featuresDetectionFullMatrix.head(5))\n",
    "display(featuresDetectionFullMatrix[6660:6690])\n",
    "print('Matrix shape:', featuresDetectionFullMatrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the **lables** array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(top_driver_data.head(5))\n",
    "display(next_driver_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver0 = top_driver_data.Driver_id.values[0]\n",
    "driver1 = next_driver_data.Driver_id.values[0]\n",
    "\n",
    "tripIdsD0 = set(top_driver_data.Trip_ID)\n",
    "numberOfTripsD0 = len(set(tripIdsD0))\n",
    "tripIdsD1 = set(next_driver_data.Trip_ID)\n",
    "numberOfTripsD1 = len(set(tripIdsD1))\n",
    "\n",
    "print(driver0 + ' made ' + str(numberOfTripsD0) + ' trips')\n",
    "print(driver1 + ' made ' + str(numberOfTripsD1) + ' trips')\n",
    "\n",
    "labels = concatLists([0]*numberOfTripsD0, [1]*numberOfTripsD1)\n",
    "print('Total number of trips: ', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add an **index** to the labels array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labelsIndex, indices = np.unique(featuresDetectionFullMatrix['Trip_ID'], return_index=True)\n",
    "indices=sorted(indices)\n",
    "# print('Shape of labelsIx =', labelsIndex.shape)\n",
    "# print('Shape of indices =', len(indices), ' type:', type(indices))\n",
    "\n",
    "labelsIndex = featuresDetectionFullMatrix['Trip_ID'][indices]\n",
    "testRange = slice(205,225)\n",
    "\n",
    "display(featuresDetectionFullMatrix[['Trip_ID', 'Absolute_Time','Speed_km_h']].loc[indices[testRange]])\n",
    "\n",
    "# Turn the labels/targets into a series, as required by the features detector\n",
    "labels = pd.Series(labels, index=labelsIndex)\n",
    "display(labels[testRange])\n",
    "\n",
    "# Compare Trip_IDs in both print outs and make sure they are equal and in same order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Extraction\n",
    "Let's take the data first and extract as many features as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check if **scaling** is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxValInData = featuresDetectionFullMatrix.max()\n",
    "minValInData = featuresDetectionFullMatrix.min()\n",
    "print('Max value:',maxValInData, 'Min value:', minValInData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to scale the time of the event in the trip, `Time_from_Trip_Start_secs` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeInEventColumn = featuresDetectionFullMatrix.Time_from_Trip_Start_secs\n",
    "maxTimeValue = timeInEventColumn.max()\n",
    "print('Normalizing time of event in trip by', maxTimeValue)\n",
    "featuresDetectionFullMatrix.Time_from_Trip_Start_secs = [scaled/maxTimeValue for scaled in timeInEventColumn]\n",
    "# Test:\n",
    "print('New max value:', featuresDetectionFullMatrix.Time_from_Trip_Start_secs.max())\n",
    "display(featuresDetectionFullMatrix[['Trip_ID', 'Absolute_Time','Speed_km_h']].loc[indices[testRange]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh import select_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundIt = False\n",
    "filename = './axl_all_features.pkl'\n",
    "try:\n",
    "    restoredFeatures = pd.read_pickle(filename)\n",
    "    axl_all_features = restoredFeatures\n",
    "    foundIt = True\n",
    "except FileNotFoundError:\n",
    "    print('Features file not found.')\n",
    "    foundIt = False\n",
    "\n",
    "if (foundIt):\n",
    "    print('** Features where restored from a previously saved file of all the features')\n",
    "else:\n",
    "    print('Start features extraction')\n",
    "    axl_all_features = extract_features(featuresDetectionFullMatrix, \n",
    "        column_id='Trip_ID', column_sort='Absolute_Time',\n",
    "        impute_function= impute)\n",
    "    axl_all_features.to_pickle(filename)\n",
    "\n",
    "\n",
    "display('All features shape: ', type(axl_all_features), axl_all_features.shape)\n",
    "display(axl_all_features.head(3))\n",
    "display(labels.head(3))\n",
    "\n",
    "display(axl_all_features.loc[:][80:85])\n",
    "display(labels[80:85])\n",
    "\n",
    "display(axl_all_features.tail(3))\n",
    "display(labels.tail(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract features** that actually have impact on the target.<br>\n",
    "To tune the number of relevant features, try adjusting the `fdr` and `ml_task` values. The FDR level that should be respected, this is the theoretical expected percentage of irrelevant features among all created features.<br>\n",
    "**F**alse **D**iscovery **R**ate is a method of conceptualizing the rate of times a true _null hypothesis_ (a false possitive finding) was incorrectly rejected. The rate of times we found relation between non-related parameters.<br>\n",
    "`ml_task`: (str) – The intended machine learning task. Either ‘classification’, ‘regression’ or ‘auto’. Defaults to '_auto_’, meaning the intended task is inferred from y. If y has a boolean, integer or object dtype, the task is assumend to be '_classification_', else '_regression_'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './axl_useful_features.pkl'\n",
    "calculatedFromScratch = True\n",
    "try:\n",
    "    axl_useful_features = pd.read_pickle(filename)\n",
    "    print('Loading useful features from file succeeded')\n",
    "    calculatedFromScratch = False\n",
    "except FileNotFoundError:\n",
    "    print('Load existing useful features from file failed. Calculating useful features.')\n",
    "    axl_useful_features = select_features(axl_all_features, labels, fdr_level=0.7,ml_task='classification' )\n",
    "    calculatedFromScratch = True\n",
    "\n",
    "samples, features = axl_useful_features.shape\n",
    "if (calculatedFromScratch):\n",
    "    if (features > 0):\n",
    "        print('Saving calculated features to file.')\n",
    "        axl_useful_features.to_pickle(filename)\n",
    "    else:\n",
    "        print('Discarding results, no useful features were found')\n",
    "\n",
    "\n",
    "print('Useful features:', type(axl_useful_features), axl_useful_features.shape)\n",
    "\n",
    "if (features>0):\n",
    "    print('So now we have', samples, 'samples of', features, 'useful features each to try prediction')\n",
    "    # display(all_features.head(3))\n",
    "    display(axl_useful_features.head(3))\n",
    "    # display(all_features.tail(3))\n",
    "    display(axl_useful_features.tail(3))\n",
    "else:\n",
    "    print(\"NO RELEVANT FEATURES FOUND. BUAAA!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We got three useful features that could help predict the targets. Let's first work witht them and later try and extract more, if results are not good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Using the Features\n",
    "Try and predic which driver drove in each trip using the useful features we found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation.\n",
    "Check if data needs **scaling**.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxT = axl_useful_features.max()\n",
    "minT = axl_useful_features.min()\n",
    "# compareT = minT\n",
    "# compareT.append(pd.Series(maxT, index=np.arange(start=3,stop=3+len(maxT))))\n",
    "display(minT)\n",
    "display(maxT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If scaling is not required.<br>\n",
    "Split the data into **train** set and **test** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(axl_useful_features, labels, test_size=.2, random_state=33)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ramdon Forest\n",
    "Let's start with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_estimators=20, max_features='auto')\n",
    "display(randomforest.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Forest\n",
    "def testForest(ranFor, trainD, trainT, testD, testT):\n",
    "    ranFor.fit(trainD, trainT)\n",
    "    predictT = ranFor.predict(testD)\n",
    "\n",
    "    print('Testing data size:', testT.shape)\n",
    "    print('Classification report of test and predicted')\n",
    "    print(metrics.classification_report(testT, predictT))\n",
    "    print(20*'____')\n",
    "    print('Confusion Matrix')\n",
    "    print(metrics.confusion_matrix(testT, predictT))\n",
    "\n",
    "testForest(randomforest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning the forests thinks '_there is no spoon_' or, there's only one driver...<br>\n",
    "**Tune the Forest**<br>\n",
    "let's tune the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degs_of_freedom = [{\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_features': ['auto', 'log2'],\n",
    "    'max_leaf_nodes': [None, 20, 50, 100, 200],\n",
    "    'oob_score': [True, False],\n",
    "#    'warm_start': [True, False]\n",
    "#     'bootstrap': [True, False] # bootstrap must be true. The GridSearch crashes if false.\n",
    "}, {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_features': ['auto', None],\n",
    "    'max_leaf_nodes': [None, 20, 50, 100, 200],\n",
    "#    'warm_start': [True, False]\n",
    "#     'bootstrap': [True, False]\n",
    "}]\n",
    "\n",
    "# cv: number of kFolds\n",
    "# n_jobs: number of parallel jobs\n",
    "gridSearch = GridSearchCV(estimator=randForest, cv=8, param_grid=degs_of_freedom, n_jobs=3)\n",
    "\n",
    "# Train \n",
    "print('Training Set Size:', y_train.shape)\n",
    "gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best score for training data:', gridSearch.best_score_)\n",
    "print('Best tree estimators:', bestForest.n_estimators, 'max features:', bestForest.max_features, 'max leaf nodes:', bestForest.max_leaf_nodes, 'oob_score', bestForest.oob_score, 'warm start:', bestForest.warm_start)\n",
    "\n",
    "bestRandomforest = gridSearch.best_estimator_\n",
    "forestScore = gridSearch.best_score_\n",
    "print('The selected forest accuracy: ', forestScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestRandomforest.fit(X_train, y_train)\n",
    "testForest(bestRandomforest, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests keep chosing the same driver all the time... resembles some people I know.<br>\n",
    "May be SVM...\n",
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialSVM = svm.SVC(kernel='rbf', random_state=RanState, C=10, gamma=0.1) #Support Vector Classifier\n",
    "testSVM(svm=initialSVM, X_test=X_test, X_train=X_train, y_test=y_test, y_train=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the SVM also sees only the first driver. Let's try tuinning the SVM before we review our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperParamsFreedom =[\n",
    "#     {\n",
    "#         'C':[25, 50, 100, 150],\n",
    "#         'gamma':[0.001, 0.005, 0.01, 0.1],\n",
    "#         'kernel':['linear', 'poly', 'sigmoid', 'rbf']\n",
    "#     }\n",
    "# ]\n",
    "# hyperParamsFreedom =[\n",
    "#     {\n",
    "#         'C':[1, 10, 100, 200],\n",
    "#         'gamma':[100, 10, 1, 0.1, 0.01],\n",
    "#         'kernel':['rbf', 'linear', 'poly', 'sigmoid']\n",
    "#     }\n",
    "# ]\n",
    "hyperParamsFreedom =[\n",
    "    {\n",
    "        'C':[1, 10, 100, 200],\n",
    "        'gamma':[100, 10, 1],\n",
    "        'kernel':['rbf', 'linear', 'poly', 'sigmoid']\n",
    "    },\n",
    "    {\n",
    "        'C':[0.1, 1, 10],\n",
    "        'gamma':[10, 1, 0.1],\n",
    "        'kernel':['rbf', 'linear', 'poly', 'sigmoid']\n",
    "    }\n",
    "]\n",
    "\n",
    "svmTuner = GridSearchCV(estimator=initialSVM, param_grid=hyperParamsFreedom, cv=8, n_jobs=3)\n",
    "svmTuner.fit(X_train, y_train)\n",
    "tunedSVM = svmTuner.best_estimator_\n",
    "\n",
    "# Let's see ...\n",
    "print('Best score for training data:', svmTuner.best_score_)\n",
    "print('Best ''C'':', tunedSVM.C)\n",
    "print('Best kernel:', tunedSVM.kernel)\n",
    "print('Best gamma:', tunedSVM.gamma)\n",
    "\n",
    "testSVM(tunedSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features extracted from the time series are worthless unless there's only one driver left in the world.<br>\n",
    "To test other features go back to the session and uncomment the relevant lines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
