{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data\n",
    "We generate 500 random x points and 500 random y points. For education purposes, the line separating \"positive\" cases from negative cases is $y = x$. We compute the class of each (x, y) point as y > x. Then we separate points by a coridor of width 1. This is done by adding vector $\\left(\\sqrt{\\frac{1}{2}}, -\\sqrt{\\frac{1}{2}}\\right)$ to points in class 0, and adding $\\left(-\\sqrt{\\frac{1}{2}}, \\sqrt{\\frac{1}{2}}\\right)$ to points in class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_y = min_x = -5\n",
    "max_y = max_x = 5\n",
    "x_coords = np.random.uniform(min_x, max_x, (500, 1))\n",
    "y_coords = np.random.uniform(min_y, max_y, (500, 1))\n",
    "clazz = np.greater(y_coords, x_coords).astype(int)\n",
    "delta = 0.5 / np.sqrt(2.0)\n",
    "x_coords = x_coords + ((0 - clazz) * delta) + ((1 - clazz) * delta)\n",
    "y_coords = y_coords + (clazz * delta) + ((clazz - 1) * delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing data\n",
    "\n",
    "Let us quickly see what we have created. We have a set of 500 points. A set of points above $y = x$ line is classified as belonging to class 1 (positive cases) and the set of points below $y = x$ belongs to class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def PlotClasses(span, delta, x, y, clazz, annotations=None):\n",
    "  fig, ax = plt.subplots(figsize=(8, 8))\n",
    "  ax.scatter(x, y, c=clazz, cmap=cm.coolwarm)\n",
    "  ax.plot(span, 1 * span + 0, 'k-')\n",
    "  ax.plot(span, 1 * span + delta, 'k,')\n",
    "  ax.plot(span, 1 * span - delta, 'k,')\n",
    "  if annotations:\n",
    "    for i, txt in enumerate(annotations):\n",
    "      ax.annotate(txt, (x[i], y[i]))\n",
    "  plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.linspace(min_x - delta, max_x + delta)\n",
    "PlotClasses(x_range, delta, x_coords, y_coords, clazz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Function\n",
    "\n",
    "The job of the input function is to feed data into SVM. It is common to all contributed Estimator classes. In case of SVM we need to provide a column that specifies the ID for each training data, and one or more vectors that return coordinates of points that we train SVM to separate. In our trivial examples (which makes it easy to visualize it) we use points on a 2D plane. In a more complex applications you could have a much higher dimentionality data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "  \"\"\"\n",
    "  The function provided input for the SVM training.\n",
    "  \n",
    "  In real life code this function would probably read batches of data and return\n",
    "  batches of IDs and feature columns. For us we simply generate all IDs in one\n",
    "  go, and create both feature columns by reshaping x_coords and y_coords into\n",
    "  a n x 1 vectors.\n",
    "  \"\"\"\n",
    "  return {\n",
    "      'example_id': tf.constant(list(map(lambda x: str(x + 1), np.arange(len(x_coords))))),\n",
    "      'x': tf.constant(np.reshape(x_coords, [x_coords.shape[0], 1])),\n",
    "      'y': tf.constant(np.reshape(y_coords, [y_coords.shape[0], 1])),\n",
    "  }, tf.constant(clazz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SVM\n",
    "\n",
    "To train SVM we need to inform it which elements of the dictionary returned by `input_fn` are features and which are labels. We create two, 1D features of real values called `x` and `y`. We have one 1D tensor that holds string labels for our examples. In our case all examples are returned at once. However, in real applications you could create a function that reads data from a file or a server and returns batches. It could also return same batches repeatedly, in which case `example_id` should reflect this. When calling the `fit` method of the estimator we also specify the number of `steps` it should run. Alternatively, we could specify `max_steps` to run. With `steps`, every time we call `fit` method, it runs the given number of steps. With `max_steps`, once the estimator was run for that number of steps any subsequent calls to `fit` exit immediately, without performing any further fitting of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrib libraries seem overly verbose. Only output errors.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "feature1 = tf.contrib.layers.real_valued_column('x')\n",
    "feature2 = tf.contrib.layers.real_valued_column('y')\n",
    "svm_classifier = tf.contrib.learn.SVM(\n",
    "  feature_columns=[feature1, feature2],\n",
    "  example_id_column='example_id')\n",
    "svm_classifier.fit(input_fn=input_fn, steps=30)\n",
    "metrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)\n",
    "print(\"Loss\", metrics['loss'], \"\\nAccuracy\", metrics['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting lables\n",
    "\n",
    "Once SVM classifier has been trained, we can use it to predict classes for n-dimentional (2 in our case) points. We create another function, `predict_fn` that returns some data that we wish SVM to classify. We run `predict` method that returns an iterable of dictionaries. Each dictionary holds two elements: `classes` and `logits`. The first one gives us the classes to which the given example belongs. The second one can be used to estimate the probability of those classes. For example, for our trivially seprable example a point $(-0.27510791, -0.4940773)$ has class 0, and logits $-0.28906667$. On the other hand $(3.39027299, -2.13721821)$, which also belongs to class 0, has logits $-7.00896215$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_predict = np.random.uniform(min_x, max_x, (20, 1))\n",
    "y_predict = np.random.uniform(min_y, max_y, (20, 1))\n",
    "\n",
    "def predict_fn():\n",
    "  return {\n",
    "    'x': tf.constant(x_predict),\n",
    "    'y': tf.constant(y_predict),\n",
    "  }\n",
    "\n",
    "pred = list(svm_classifier.predict(input_fn=predict_fn))\n",
    "predicted_class = map(lambda x: x['classes'], pred)\n",
    "annotations = map(lambda x: '%.2f' % x['logits'][0], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_class = list(predicted_class)\n",
    "#eex = np.arange(1,len(lista)+1)\n",
    "predicted_class = np.array(predicted_class, dtype=int)\n",
    "predicted_class = np.reshape(predicted_class, [len(predicted_class), 1])\n",
    "# predicted_class\n",
    "#lista = list(annotations)\n",
    "#ccc = np.array(lista)\n",
    "#ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotClasses(x_range, delta, x_predict, y_predict, predicted_class, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
